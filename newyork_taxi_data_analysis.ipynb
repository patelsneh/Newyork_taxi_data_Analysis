{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "newyork_taxi_data_analysis.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLXBPNw2Axj2"
      },
      "source": [
        "# New York Taxi Data Analysis \n",
        "Group-9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj8t_14LAxj7"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFhnzdWhAxj8"
      },
      "source": [
        "# generic modules\n",
        "import itertools\n",
        "import os\n",
        "import re\n",
        "import timeit\n",
        "import gc\n",
        "\n",
        "# specific module\n",
        "#import wget\n",
        "\n",
        "# common ds modules\n",
        "import pandas as pd\n",
        "#import plotly.express as px\n",
        "\n",
        "# spark modules for session managment\n",
        "from pyspark import SparkConf\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# spark functions\n",
        "from pyspark.sql.functions import lit\n",
        "import pyspark.sql.functions as sparkle\n",
        "\n",
        "# spark types\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# spark ml\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "from pyspark.ml.regression import GBTRegressor\n",
        "from pyspark.ml.evaluation import RegressionEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXqRsDpYAxj9",
        "outputId": "d3ac897d-5f27-4191-8f8e-471e6f2b457d"
      },
      "source": [
        "# session starter named nyctaxi\n",
        "spark=SparkSession.builder \\\n",
        "    .appName('nyctaxi') \\\n",
        "    .master('local[*]') \\\n",
        "    .config('spark.driver.memory','10G') \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "#     .config(\"spark.sql.default.parallelism\", \"360\") \\ \n",
        "'''\n",
        ".config(\"spark.driver.maxResultSize\", \"8g\") \\\n",
        "    \n",
        "    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"150000\") \\\n",
        "    .config(\"spark.sql.tungsten.enabled\", \"true\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"360\") \\\n",
        "    .config(\"spark.rdd.compress\", \"true\") \\\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n.config(\"spark.driver.maxResultSize\", \"8g\")     \\n    .config(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")     .config(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"150000\")     .config(\"spark.sql.tungsten.enabled\", \"true\")     .config(\"spark.sql.shuffle.partitions\", \"360\")     .config(\"spark.rdd.compress\", \"true\") '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxUWZSt8Axj_"
      },
      "source": [
        "## Download Data from the website in to docker container\n",
        "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRnCvTaKAxj_",
        "outputId": "5ade4ced-827e-485b-cb02-9663c7818fd0"
      },
      "source": [
        "#spark.read.csv(\"Dataset/yellow-2019-01.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[_c0: string, _c1: string, _c2: string, _c3: string, _c4: string, _c5: string, _c6: string, _c7: string, _c8: string, _c9: string, _c10: string, _c11: string, _c12: string, _c13: string, _c14: string, _c15: string, _c16: string, _c17: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kATqWIbAxkA"
      },
      "source": [
        "## Converting CSV to Initial Parquet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9ZDXFN4AxkE"
      },
      "source": [
        "# reads directory, filters for csv's and feeds into loop to convert to parquet\n",
        "files=[re.search(r\"(.*)(\\.csv)$\", file).group(1) for file in os.listdir(\"./Dataset/\") if file.endswith(\".csv\")]\n",
        "for file in files:\n",
        "    inpath = f\"./Dataset/{file}.csv\"\n",
        "    readdf = spark.read.csv(inpath, header = \"true\")\n",
        "    outpath = f\"./Dataset/prq/{file}.parquet\"\n",
        "    readdf.write.parquet(outpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnG7v_JsAxkF"
      },
      "source": [
        "colours=['yellow']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bza2JGJ-AxkG"
      },
      "source": [
        "## Combining Dirty Data with color of taxi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rflFS2VAxkH"
      },
      "source": [
        "# combines month data into single file per colour\n",
        "for colour in colours:\n",
        "    # uses a sample of the first dataset to create and empty df with correct format to join to\n",
        "    initpath = f\"./Dataset/prq/{colour}-2019-01.parquet\"\n",
        "    outdf = spark.read.parquet(initpath)\n",
        "    outdf = outdf.limit(0)\n",
        "    # get files for loop\n",
        "    files = [re.search(r\"(.*)(\\.parquet)$\", file).group(1) for file in os.listdir(\"./Dataset/prq\") if file.endswith(\".parquet\") and file.startswith(colour)]\n",
        "    for file in files:\n",
        "        inpath = f\"./Dataset/prq/{file}.parquet\"\n",
        "        readdf = spark.read.parquet(inpath)\n",
        "        # !! unionByName !! ensures columns match union method can result in incorrect mapping\n",
        "        outdf = outdf.unionByName(readdf)\n",
        "    outpath = f\"./data/{colour}-all.parquet\"\n",
        "    outdf.write.parquet(outpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1852zlTZAxkI",
        "outputId": "61f2e2e5-6404-49bb-d155-9183f7188279"
      },
      "source": [
        "# read and check columns\n",
        "yellowdf = spark.read.parquet(\"./data/yellow-all.parquet\")\n",
        "yellowdf.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'tpep_pickup_datetime',\n",
              " 'tpep_dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'store_and_fwd_flag',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'congestion_surcharge']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uvdZ5jEAxkJ"
      },
      "source": [
        "# pass data to next stage\n",
        "data = yellowdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5Pogpn3AxkK"
      },
      "source": [
        "## Uncleaned Full Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ugRgdXFAxkK",
        "outputId": "c50a2c87-2714-4967-8100-2233a6273b05"
      },
      "source": [
        "# check record numbers match\n",
        "data.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7667792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzWkZDFoAxkM"
      },
      "source": [
        "# transform dataframe \n",
        "# add new missing columns with releveant value\n",
        "yellowdf = yellowdf.withColumn('trip_type', lit(\"1\"))\n",
        "yellowdf = yellowdf.withColumn('ehail_fee', lit(\"0\"))\n",
        "# create colour variable to track dataset\n",
        "yellowdf = yellowdf.withColumn('colour', lit(\"yellow\"))\n",
        "yellowdf = yellowdf.withColumnRenamed(\"tpep_pickup_datetime\", \"pickup_datetime\")\n",
        "yellowdf = yellowdf.withColumnRenamed(\"tpep_dropoff_datetime\", \"dropoff_datetime\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sedj3dAyAxkN"
      },
      "source": [
        "# pass data to next stage\n",
        "data = yellowdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loN97CxXAxkO",
        "outputId": "1227348f-a48c-41c5-f038-fa2cccd3df59"
      },
      "source": [
        "# intial schema not imputed as no cleaning done\n",
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: string (nullable = true)\n",
            " |-- pickup_datetime: string (nullable = true)\n",
            " |-- dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: string (nullable = true)\n",
            " |-- trip_distance: string (nullable = true)\n",
            " |-- RatecodeID: string (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: string (nullable = true)\n",
            " |-- DOLocationID: string (nullable = true)\n",
            " |-- payment_type: string (nullable = true)\n",
            " |-- fare_amount: string (nullable = true)\n",
            " |-- extra: string (nullable = true)\n",
            " |-- mta_tax: string (nullable = true)\n",
            " |-- tip_amount: string (nullable = true)\n",
            " |-- tolls_amount: string (nullable = true)\n",
            " |-- improvement_surcharge: string (nullable = true)\n",
            " |-- total_amount: string (nullable = true)\n",
            " |-- congestion_surcharge: string (nullable = true)\n",
            " |-- trip_type: string (nullable = false)\n",
            " |-- ehail_fee: string (nullable = false)\n",
            " |-- colour: string (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH-uokrCAxkP"
      },
      "source": [
        "# create view for spark.sql queries\n",
        "data.createOrReplaceTempView(\"data_init_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__BNsjV5AxkQ"
      },
      "source": [
        "## Grouping by Colour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tb2LFuIAxkS",
        "outputId": "f112d84e-88f4-4126-b04b-ea5636dd224b"
      },
      "source": [
        "# SQL query, group by relevent variable and create count to check splits\n",
        "spark.sql(\"\"\"\n",
        "            SELECT colour, count(colour)\n",
        "            FROM data_init_view\n",
        "            GROUP by colour\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|colour|count(colour)|\n",
            "+------+-------------+\n",
            "|yellow|      7667792|\n",
            "+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8oO5JvzAxkT"
      },
      "source": [
        "## VendorID\n",
        "Should be 1 or 2\n",
        "   - 1-Creative Mobile Technologies\n",
        "   - 2-Verifone INC.\n",
        "    \n",
        "- VendorId=4 contains 230,613 records?\n",
        "- Ratecodes include 99 for VendorId=4 which is invalid it should be in range of 1-6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At2QrTr6AxkV",
        "outputId": "d656ddba-d771-4815-dd78-86c67e0e31b7"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT VendorID, count(VendorID)\n",
        "            FROM data_init_view\n",
        "            GROUP by VendorID\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+\n",
            "|VendorID|count(VendorID)|\n",
            "+--------+---------------+\n",
            "|       1|        2938778|\n",
            "|       4|          76823|\n",
            "|       2|        4652191|\n",
            "+--------+---------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0wYaFa_AxkW",
        "outputId": "30bf3e9a-268e-40ae-d17d-d009a8e7c867"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE VendorID == 4\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|       4|2019-01-25 17:00:59|2019-01-25 17:04:53|              1|          .58|         1|                 N|         237|         262|           2|        4.5|    1|    0.5|         0|           0|                  0.3|         6.3|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:10:44|2019-01-25 17:15:40|              1|          .76|         1|                 N|         262|         236|           2|          5|    1|    0.5|         0|           0|                  0.3|         6.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:19:17|2019-01-25 17:33:24|              1|         2.87|         1|                 N|         237|          41|           1|         12|    1|    0.5|         2|           0|                  0.3|        15.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:00:30|2019-01-25 17:06:48|              1|          .65|         1|                 N|         163|         230|           2|        5.5|    1|    0.5|         0|           0|                  0.3|         7.3|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:09:49|2019-01-25 17:19:38|              1|         1.97|         1|                 N|         230|          68|           1|        8.5|    1|    0.5|       1.5|           0|                  0.3|        11.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:29:57|2019-01-25 17:35:34|              1|          .84|         1|                 N|          68|         246|           1|        5.5|    1|    0.5|         1|           0|                  0.3|         8.3|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:39:09|2019-01-25 17:46:31|              1|         1.07|         1|                 N|         246|         186|           1|          7|    1|    0.5|         1|           0|                  0.3|         9.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:56:18|2019-01-25 18:08:10|              1|         1.44|         1|                 N|         186|         163|           2|          9|    1|    0.5|         0|           0|                  0.3|        10.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:03:13|2019-01-25 17:12:16|              1|         1.40|         1|                 N|         113|         137|           1|          8|    1|    0.5|      1.96|           0|                  0.3|       11.76|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:19:07|2019-01-25 17:33:57|              1|         1.24|         1|                 N|         170|         161|           2|         10|    1|    0.5|         0|           0|                  0.3|        11.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:34:29|2019-01-25 17:43:32|              1|         1.49|         1|                 N|         161|         143|           1|          8|    1|    0.5|      1.96|           0|                  0.3|       11.76|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:59:49|2019-01-25 18:12:17|              2|         1.27|         1|                 N|         230|         170|           2|          9|    1|    0.5|         0|           0|                  0.3|        10.8|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:27:23|2019-01-25 17:33:47|              1|          .37|         1|                 N|         237|         162|           2|        5.5|    1|    0.5|         0|           0|                  0.3|         7.3|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:36:03|2019-01-25 17:46:36|              1|         1.26|         1|                 N|         162|         163|           1|          8|    1|    0.5|      2.94|           0|                  0.3|       12.74|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:49:49|2019-01-25 17:59:25|              1|         1.06|         1|                 N|         163|         141|           1|        7.5|    1|    0.5|      1.86|           0|                  0.3|       11.16|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:16:15|2019-01-25 17:33:08|              1|         1.29|         1|                 N|         100|         249|           1|       11.5|    1|    0.5|      2.66|           0|                  0.3|       15.96|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:44:03|2019-01-25 17:49:12|              1|          .28|         1|                 N|          90|          90|           2|        4.5|    1|    0.5|         0|           0|                  0.3|         6.3|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:59:34|2019-01-25 18:10:18|              1|         1.19|         1|                 N|         186|         170|           1|        8.5|    1|    0.5|      2.06|           0|                  0.3|       12.36|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:07:58|2019-01-25 17:57:40|              1|         9.32|         1|                 N|         138|         230|           2|         35|    1|    0.5|         0|        5.76|                  0.3|       42.56|                null|        1|        0|yellow|\n",
            "|       4|2019-01-25 17:41:20|2019-01-25 18:02:32|              1|         2.31|         1|                 N|         162|         246|           1|       14.5|    1|    0.5|      3.26|           0|                  0.3|       19.56|                null|        1|        0|yellow|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weNJ-q76AxkX",
        "outputId": "6c5f5eb8-b84b-4ed4-e6df-269699afe0db"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT colour, count(colour)\n",
        "            FROM data_init_view\n",
        "            WHERE VendorID == 4\n",
        "            GROUP by colour\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-------------+\n",
            "|colour|count(colour)|\n",
            "+------+-------------+\n",
            "|yellow|        76823|\n",
            "+------+-------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4SEuLR8AxkZ",
        "outputId": "62eb1af8-d1ce-462e-eabf-416521634f32"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT RatecodeID, count(RatecodeID)\n",
        "            FROM data_init_view\n",
        "            WHERE VendorID == 4\n",
        "            GROUP by RatecodeID\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----------------+\n",
            "|RatecodeID|count(RatecodeID)|\n",
            "+----------+-----------------+\n",
            "|         3|               78|\n",
            "|        99|                5|\n",
            "|         5|              225|\n",
            "|         1|            75240|\n",
            "|         4|               46|\n",
            "|         2|             1229|\n",
            "+----------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbKkeWspAxka",
        "outputId": "7369b5ce-57e7-4d30-e022-ac4cb79724b1"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT passenger_count, count(passenger_count)\n",
        "            FROM data_init_view\n",
        "            WHERE VendorID == 4\n",
        "            GROUP by passenger_count\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+----------------------+\n",
            "|passenger_count|count(passenger_count)|\n",
            "+---------------+----------------------+\n",
            "|              3|                   266|\n",
            "|              5|                     9|\n",
            "|              1|                 75449|\n",
            "|              4|                   107|\n",
            "|              2|                   992|\n",
            "+---------------+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_S_ispwAxkc",
        "outputId": "736d0719-8e66-4685-fab6-cfbe6e78491b"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMPORARY VIEW vid4months\n",
        "            AS\n",
        "            SELECT pickup_datetime,\n",
        "                CASE\n",
        "                    WHEN pickup_datetime LIKE '%2019-01%' THEN 'jan'\n",
        "                    ELSE \"unknown\"\n",
        "                END AS MonthGroup\n",
        "            FROM data_init_view\n",
        "            WHERE VendorID == 4\n",
        "        \"\"\")\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            SELECT MonthGroup, count(MonthGroup) as count\n",
        "            FROM vid4months\n",
        "            GROUP BY MonthGroup\n",
        "            ORDER BY count\n",
        "        \"\"\").show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----+\n",
            "|MonthGroup|count|\n",
            "+----------+-----+\n",
            "|       jan|76823|\n",
            "+----------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwmPdxGJAxkd"
      },
      "source": [
        "## Passenger Count\n",
        "- 657,274 records of passenger count 0\n",
        "- For 7-9 passenger count\n",
        "    - ~350 records( What are they Maxi Type?)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twzvOgT_Axke",
        "outputId": "e52b5140-642d-45b1-ab39-43bd31fbb212"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT passenger_count, count(passenger_count)\n",
        "            FROM data_init_view\n",
        "            GROUP by passenger_count\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+----------------------+\n",
            "|passenger_count|count(passenger_count)|\n",
            "+---------------+----------------------+\n",
            "|              7|                    19|\n",
            "|              3|                314721|\n",
            "|              8|                    29|\n",
            "|              0|                117381|\n",
            "|              5|                323842|\n",
            "|              6|                200811|\n",
            "|              9|                     9|\n",
            "|              1|               5456121|\n",
            "|              4|                140753|\n",
            "|              2|               1114106|\n",
            "+---------------+----------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJS47VbAxkg"
      },
      "source": [
        "## RatecodeID should be in range(1-6)\n",
        "- 1271 with RatecodeID=99\n",
        "- 693 with distance 0\n",
        "- 394 PULocation 264"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-_QV8i1Axkh",
        "outputId": "027579b6-8ca4-4fb0-dcae-275ba19aee3e"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT RatecodeID, count(RatecodeID)\n",
        "            FROM data_init_view\n",
        "            GROUP by RatecodeID\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+-----------------+\n",
            "|RatecodeID|count(RatecodeID)|\n",
            "+----------+-----------------+\n",
            "|         3|            11801|\n",
            "|        99|              252|\n",
            "|         5|            54569|\n",
            "|         6|               46|\n",
            "|         1|          7430139|\n",
            "|         4|             4895|\n",
            "|         2|           166090|\n",
            "+----------+-----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhDRx1lKAxkh",
        "outputId": "ef007c27-c090-4064-9ef4-2ff594297274"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT colour, count(colour) as count\n",
        "            FROM data_init_view\n",
        "            WHERE NOT RatecodeID BETWEEN 1 AND 6\n",
        "            GROUP BY colour\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|colour|count|\n",
            "+------+-----+\n",
            "|yellow|  252|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mgXB47sAxkj",
        "outputId": "96cc58a0-2c16-4d51-8dfd-620b9150c14b"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT trip_distance, count(trip_distance) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE NOT RatecodeID BETWEEN 1 AND 6\n",
        "            GROUP by trip_distance\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+-----+\n",
            "|trip_distance|count|\n",
            "+-------------+-----+\n",
            "|          .00|  145|\n",
            "|          .84|    4|\n",
            "|         1.27|    4|\n",
            "|         1.35|    3|\n",
            "|          .66|    2|\n",
            "|          .72|    2|\n",
            "|          .74|    2|\n",
            "|         1.50|    2|\n",
            "|          .94|    2|\n",
            "|          .73|    2|\n",
            "|         3.84|    2|\n",
            "|         2.57|    2|\n",
            "|         2.19|    2|\n",
            "|         1.18|    2|\n",
            "|         1.52|    2|\n",
            "|         2.78|    1|\n",
            "|         1.30|    1|\n",
            "|        23.89|    1|\n",
            "|         1.68|    1|\n",
            "|         1.74|    1|\n",
            "+-------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxMd8qeUAxkk",
        "outputId": "49e154c4-838c-4983-9bad-baee3e924b43"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT PULocationID, count(PULocationID) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE NOT RatecodeID BETWEEN 1 AND 6\n",
        "            GROUP by PULocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-----+\n",
            "|PULocationID|count|\n",
            "+------------+-----+\n",
            "|         264|   84|\n",
            "|         265|   16|\n",
            "|         142|    8|\n",
            "|         239|    8|\n",
            "|         170|    7|\n",
            "|          43|    7|\n",
            "|          79|    7|\n",
            "|         231|    6|\n",
            "|         162|    6|\n",
            "|         230|    6|\n",
            "|         138|    5|\n",
            "|         193|    5|\n",
            "|         132|    5|\n",
            "|         107|    5|\n",
            "|         161|    5|\n",
            "|         234|    4|\n",
            "|         141|    4|\n",
            "|         237|    4|\n",
            "|         145|    4|\n",
            "|         238|    3|\n",
            "+------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo0SFmRqAxkk"
      },
      "source": [
        "## Payment Type should be in range(1-6)\n",
        "- All valid within range\n",
        "- No 6 \n",
        "- Count descends as the payment type increases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESYQRYKvAxkl",
        "outputId": "5bec7098-56d8-4ff2-b46c-c26815fd4589"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT payment_type, count(payment_type) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by payment_type\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+-------+\n",
            "|payment_type|  count|\n",
            "+------------+-------+\n",
            "|           1|5486027|\n",
            "|           2|2137415|\n",
            "|           3|  33186|\n",
            "|           4|  11164|\n",
            "+------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKLMzyabAxkm"
      },
      "source": [
        "## Extra, it should be 0.5 or 1\n",
        "- If all the values is valid then we can change to two bools[]\n",
        "- Out of range value including negatives, Overnight Charges?\n",
        "- 101 unique values \n",
        "- 19 negative values\n",
        "- Valid values\n",
        "    - 4598696 records contains 1\n",
        "    - 7902055 records contains 0.2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T31u229UAxkn",
        "outputId": "6f741bc1-2adf-41b0-cf83-205946d4ab12"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT extra, count(extra) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by extra\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+\n",
            "|extra|  count|\n",
            "+-----+-------+\n",
            "|    0|4199855|\n",
            "|  0.5|2116494|\n",
            "|    1|1316580|\n",
            "|  4.5|  31241|\n",
            "| -0.5|   2201|\n",
            "|   -1|    863|\n",
            "|  0.8|    229|\n",
            "| -4.5|     79|\n",
            "|  1.3|     74|\n",
            "| 17.5|     63|\n",
            "|  1.8|     34|\n",
            "|  2.5|     21|\n",
            "|  0.3|     10|\n",
            "|   18|      9|\n",
            "|    3|      7|\n",
            "| 18.5|      6|\n",
            "|  5.3|      4|\n",
            "|  0.2|      3|\n",
            "| 0.25|      1|\n",
            "| 10.9|      1|\n",
            "+-----+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMB5aMiVAxkn",
        "outputId": "ce12b9a4-e31a-497a-f498-fca7bddb8010"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT extra, count(extra) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by extra\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRtWLfrFAxko",
        "outputId": "ca1484d5-3471-4fab-ec2e-dab52b6b9e7e"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT extra, count(extra) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE extra < 0\n",
        "            GROUP by extra\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hz0XRBDKAxkp"
      },
      "source": [
        "## Mta_Tax should be 0.5\n",
        "- If all values are valid change to bool[]\n",
        "- 37262299 valid values\n",
        "- 203257: 0 values\n",
        "- 52388: -0.5 value(Refund?)\n",
        "    - Check other out of range and negative values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDkV1GOsAxkp",
        "outputId": "9079e64e-7708-49b2-a5c3-d2083b4c4a02"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT mta_tax, count(mta_tax) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by mta_tax\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+-------+\n",
            "|mta_tax|  count|\n",
            "+-------+-------+\n",
            "|    0.5|7625883|\n",
            "|      0|  34984|\n",
            "|   -0.5|   6819|\n",
            "|   0.25|     97|\n",
            "|   0.35|      2|\n",
            "|  32.53|      1|\n",
            "|  37.51|      1|\n",
            "|    0.9|      1|\n",
            "|   2.42|      1|\n",
            "|   60.8|      1|\n",
            "|      1|      1|\n",
            "|   18.3|      1|\n",
            "+-------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJtAYOK4Axkq"
      },
      "source": [
        "### Out of range value\n",
        "- 52556: Out of range value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wQrHIR5Axkq",
        "outputId": "dbadd2b6-28e4-4156-fd52-fcdf20a907b1"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT colour, count(colour) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE mta_tax != \"0\"\n",
        "            AND mta_tax != \"0.5\"\n",
        "            GROUP by colour\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|colour|count|\n",
            "+------+-----+\n",
            "|yellow| 6925|\n",
            "+------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wm9aEgWPAxkr"
      },
      "source": [
        "## Improvement_Surcharge should be 0.3\n",
        "- If all values are valid change to bool[]\n",
        "- 37447079 valid 0.3 values\n",
        "- 53940: -0.3 value(Refund?)\n",
        "- 17076: 0 value\n",
        "- 16: 1 value\n",
        "    - All 0 trip_diatance\n",
        "    - All PU/Do Id= 265"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oatzOL5MAxks",
        "outputId": "7b879139-ab98-48bb-e3f7-6ae137d142b8"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT improvement_surcharge, count(improvement_surcharge) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by improvement_surcharge\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+-------+\n",
            "|improvement_surcharge|  count|\n",
            "+---------------------+-------+\n",
            "|                  0.3|7658005|\n",
            "|                 -0.3|   7129|\n",
            "|                    0|   2657|\n",
            "|                  0.6|      1|\n",
            "+---------------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYgC_YCAAxkt",
        "outputId": "0a85f856-efe0-4be6-eba2-1d290ed4c948"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE improvement_surcharge = \"1\"\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0dE0etjAxkz"
      },
      "source": [
        "## Trip Type should be 1 for Yellow Taxi\n",
        "- All are valid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wa7HlP2BAxkz",
        "outputId": "7b3dc82b-6a01-46dd-de87-39c4ac627e28"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT trip_type, count(trip_type) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by trip_type\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------+-------+\n",
            "|trip_type|  count|\n",
            "+---------+-------+\n",
            "|        1|7667792|\n",
            "+---------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ujnluXzAxk0"
      },
      "source": [
        "## Check Location Value\n",
        "(Should be an integer from 1-265)- from Taxizone lookup Table:-\n",
        "    https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
        "- PULocationID\n",
        "- DULocationID\n",
        "- Both\n",
        "    - No non integer values \n",
        "    - No null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx8pQeAJAxk0",
        "outputId": "715b909c-812b-4f01-e10f-103251c3aa7f"
      },
      "source": [
        "# look for non integer values\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE PULocationID BETWEEN 1 AND 265\n",
        "            and mod(PULocationID, 1) != 0\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YciWQNKcAxk1",
        "outputId": "0daa5f61-5f34-4e10-b184-912af601cc08"
      },
      "source": [
        "# count of location values, most first\n",
        "spark.sql(\"\"\"\n",
        "            SELECT PULocationID, count(PULocationID) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by PULocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|PULocationID| count|\n",
            "+------------+------+\n",
            "|         237|332473|\n",
            "|         236|323008|\n",
            "|         161|312392|\n",
            "|         162|277166|\n",
            "|         230|263646|\n",
            "|         186|260712|\n",
            "|          48|240903|\n",
            "|         170|238978|\n",
            "|         234|237648|\n",
            "|         142|235144|\n",
            "|         239|207883|\n",
            "|         163|199682|\n",
            "|         132|196612|\n",
            "|          79|193955|\n",
            "|         141|192380|\n",
            "|         138|184334|\n",
            "|         107|176786|\n",
            "|         164|172647|\n",
            "|          68|171971|\n",
            "|         238|162192|\n",
            "+------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzUwMLFtAxk2",
        "outputId": "1434b939-ebac-40fc-dfd5-92368309c37f"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE NOT DOLocationID BETWEEN 1 AND 265\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl1Rcj12Axk3",
        "outputId": "2b8a28e8-7eac-4b92-d068-27aa08f98fc2"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT DOLocationID, count(DOLocationID) AS count\n",
        "            FROM data_init_view\n",
        "            GROUP by DOLocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|DOLocationID| count|\n",
            "+------------+------+\n",
            "|         236|334323|\n",
            "|         237|296185|\n",
            "|         161|293782|\n",
            "|         170|242037|\n",
            "|         162|232451|\n",
            "|         230|225336|\n",
            "|         142|214164|\n",
            "|          48|208624|\n",
            "|         234|204386|\n",
            "|         239|204350|\n",
            "|         141|202184|\n",
            "|         186|189486|\n",
            "|         163|175754|\n",
            "|         238|175310|\n",
            "|          79|168608|\n",
            "|          68|167144|\n",
            "|         107|162697|\n",
            "|         263|158297|\n",
            "|         164|154200|\n",
            "|         140|152042|\n",
            "+------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d2leJb5Axk4",
        "outputId": "c5277608-42bf-4bda-d5bb-a8b580356368"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT DOLocationID, count(DOLocationID) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE DOLocationID >= 264\n",
        "            GROUP by DOLocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|DOLocationID| count|\n",
            "+------------+------+\n",
            "|         264|149094|\n",
            "|         265| 16817|\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qh2BmwbtAxk5"
      },
      "source": [
        "## Check dates are within range:-\n",
        "(Should be 2019-01-01 00:00:00 to 2019-05-31 23:59:59)\n",
        "- Pickup_datetime\n",
        "    - min 2001-01-01 00:09:39\n",
        "        -\n",
        "    - Max 2088-01-24 00:25:39\n",
        "        -\n",
        "- Dropoff_datetime\n",
        "    - min 2001-01-01 06:39:54\n",
        "        -\n",
        "    - Max 2088-01-24 07:28:25\n",
        "        -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaxMv9nSAxk5",
        "outputId": "2b4be2b2-58b5-4af9-da7f-b1e9add2721b"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT MIN(pickup_datetime), MAX(pickup_datetime), MIN(dropoff_datetime),  MAX(dropoff_datetime)\n",
        "            FROM data_init_view\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+---------------------+---------------------+\n",
            "|min(pickup_datetime)|max(pickup_datetime)|min(dropoff_datetime)|max(dropoff_datetime)|\n",
            "+--------------------+--------------------+---------------------+---------------------+\n",
            "| 2001-02-02 14:55:07| 2088-01-24 00:25:39|  2001-02-02 15:07:27|  2088-01-24 07:28:25|\n",
            "+--------------------+--------------------+---------------------+---------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74QTGYyHAxk5",
        "outputId": "c37c33c2-c62f-4f02-c14d-1ac4749dd9b8"
      },
      "source": [
        "# calculate tripdays using datediff (simpler)\n",
        "spark.sql(\"\"\"\n",
        "            WITH tripdaysTable AS (\n",
        "            SELECT *, datediff(dropoff_datetime, pickup_datetime) as tripdays\n",
        "            FROM data_init_view\n",
        "            )\n",
        "            SELECT tripdays, count(tripdays) AS count\n",
        "            FROM tripdaysTable\n",
        "            GROUP by tripdays\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------+\n",
            "|tripdays|  count|\n",
            "+--------+-------+\n",
            "|       0|7597276|\n",
            "|       1|  70508|\n",
            "|     -58|      1|\n",
            "|      -2|      1|\n",
            "|     -19|      1|\n",
            "|      30|      1|\n",
            "|      22|      1|\n",
            "|      24|      1|\n",
            "|       5|      1|\n",
            "|       2|      1|\n",
            "+--------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fP31T_-Axk6",
        "outputId": "0dd1402e-c7d7-4440-d90c-f65d468b537e"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            WITH countsTable AS (\n",
        "                WITH tripdaysTable AS (\n",
        "                    SELECT *, datediff(dropoff_datetime, pickup_datetime) as tripdays\n",
        "                    FROM data_init_view\n",
        "                    )\n",
        "                SELECT tripdays, count(tripdays) AS count\n",
        "                FROM tripdaysTable\n",
        "                GROUP by tripdays\n",
        "                ORDER BY count DESC\n",
        "            )\n",
        "            SELECT sum(count)\n",
        "            FROM countsTable\n",
        "            WHERE tripdays != \"0\"\n",
        "            AND tripdays != \"1\"\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------+\n",
            "|sum(count)|\n",
            "+----------+\n",
            "|         8|\n",
            "+----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt7Ffbh6Axk-",
        "outputId": "7ce1dea6-6c86-4c0d-d773-0b7f07e82e1a"
      },
      "source": [
        "# inspect out of range values\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE pickup_datetime < \"2019-01-01 00:00:00\"\n",
        "            ORDER BY pickup_datetime DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|       2|2018-12-31 23:59:58|2019-01-01 00:03:52|              1|          .66|         1|                 N|         162|         170|           2|        4.5|  0.5|    0.5|         0|           0|                  0.3|         5.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:57|2019-01-01 00:22:00|              1|         8.37|         1|                 N|         239|         235|           2|         26|  0.5|    0.5|         0|           0|                  0.3|        27.3|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:57|2019-01-01 00:00:00|              4|          .00|         5|                 N|         264|         265|           1|        121|    0|    0.5|     36.54|           0|                  0.3|      158.34|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:52|2019-01-01 00:00:29|              1|          .06|         1|                 N|         164|         164|           1|        2.5|  0.5|    0.5|         0|           0|                  0.3|         3.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:52|2019-01-01 00:13:08|              3|         3.32|         1|                 N|           7|         129|           2|       12.5|  0.5|    0.5|         0|           0|                  0.3|        13.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:51|2019-01-01 00:03:48|              2|          .35|         1|                 N|         249|         249|           1|          4|  0.5|    0.5|      1.06|           0|                  0.3|        6.36|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:47|2019-01-01 00:13:02|              1|         4.46|         1|                 N|          65|          79|           2|         15|  0.5|    0.5|         0|           0|                  0.3|        16.3|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:46|2019-01-01 00:08:54|              2|         1.06|         1|                 N|         161|         142|           2|        7.5|  0.5|    0.5|         0|           0|                  0.3|         8.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:38|2019-01-01 00:14:29|              1|          .61|         1|                 N|          68|          68|           1|         10|  0.5|    0.5|      2.26|           0|                  0.3|       13.56|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:38|2019-01-01 00:13:31|              2|         6.90|         1|                 N|         132|         197|           2|       20.5|  0.5|    0.5|         0|           0|                  0.3|        21.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:38|2019-01-01 00:50:35|              1|         3.97|         1|                 N|         142|          79|           2|         29|  0.5|    0.5|         0|           0|                  0.3|        30.3|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:36|2019-01-01 00:16:24|              1|         3.77|         1|                 N|          48|         263|           1|         15|  0.5|    0.5|         2|           0|                  0.3|        18.3|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:36|2019-01-01 00:23:51|              1|        12.95|         1|                 N|         148|         136|           2|       36.5|  0.5|    0.5|         0|           0|                  0.3|        37.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:31|2019-01-01 00:13:13|              1|         4.54|         1|                 N|          48|          74|           2|       14.5|  0.5|    0.5|         0|           0|                  0.3|        15.8|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:30|2019-01-01 00:03:09|              1|         1.06|         1|                 N|         229|         140|           1|          5|  0.5|    0.5|      1.89|           0|                  0.3|        8.19|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:30|2019-01-01 00:04:09|              1|         1.27|         1|                 N|          68|         158|           1|          6|  0.5|    0.5|      1.46|           0|                  0.3|        8.76|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:26|2019-01-01 00:13:26|              2|         2.24|         1|                 N|         186|         224|           1|         11|  0.5|    0.5|      3.08|           0|                  0.3|       15.38|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:24|2019-01-01 00:31:15|              2|        21.09|         2|                 N|         132|         243|           2|         52|    0|    0.5|         0|        5.76|                  0.3|       58.56|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:23|2019-01-01 00:07:25|              1|         3.04|         1|                 N|          79|         140|           1|         10|  0.5|    0.5|      2.82|           0|                  0.3|       14.12|                null|        1|        0|yellow|\n",
            "|       2|2018-12-31 23:59:19|2019-01-01 00:04:32|              1|          .90|         1|                 N|         148|          79|           2|        5.5|  0.5|    0.5|         0|           0|                  0.3|         6.8|                null|        1|        0|yellow|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqpBRw6NAxk_",
        "outputId": "aaeee5e1-a196-433e-e451-e89a020cf5b9"
      },
      "source": [
        "# count high out of range values\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE pickup_datetime > \"2019-12-31 23:59:59\" \n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP21_dffAxlA",
        "outputId": "a7f94892-811e-4e8d-aef0-f115fdc8aa23"
      },
      "source": [
        "# count low out of range values\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE pickup_datetime < \"2019-01-01 00:00:00\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGJhTZHPAxlB",
        "outputId": "2a752235-7dd8-4776-c66a-15cab21b1971"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE dropoff_datetime < \"2019-01-01 00:00:00\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-Soig24AxlC",
        "outputId": "cbc7986a-eebb-49cf-a20a-cc4e4593e2e7"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE dropoff_datetime > \"2019-01-31 23:59:59\" \n",
        "            ORDER BY dropoff_datetime\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3011"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dryUbtXnAxlD",
        "outputId": "6c8ec56f-5287-48d7-fd7b-46330b8d4901"
      },
      "source": [
        "# investigate nye values\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE dropoff_datetime > \"2019-01-31 23:59:59\"\n",
        "            AND pickup_datetime < \"2019-01-31 23:59:59\" \n",
        "            ORDER BY dropoff_datetime\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2915"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9ZjIltPAxlE",
        "outputId": "97586c7d-435a-4126-b556-05f90670204f"
      },
      "source": [
        "# show a candiate value to evaluate\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE dropoff_datetime > \"2020-01-01 23:59:59\"\n",
        "            AND pickup_datetime < \"2019-12-31 23:59:59\" \n",
        "            ORDER BY dropoff_datetime\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "|VendorID|pickup_datetime|dropoff_datetime|passenger_count|trip_distance|RatecodeID|store_and_fwd_flag|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|congestion_surcharge|trip_type|ehail_fee|colour|\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "+--------+---------------+----------------+---------------+-------------+----------+------------------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+--------------------+---------+---------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN32g1QmAxlF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YovJSOczAxlG",
        "outputId": "f3c938fe-aa50-452b-8c33-91c93f001ae2"
      },
      "source": [
        "# count where pickup location was unknown\n",
        "spark.sql(\"\"\"\n",
        "            SELECT PULocationID, count(PULocationID) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE PULocationID = \"264\"\n",
        "            OR PULocationID = \"265\"\n",
        "            GROUP by PULocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|PULocationID| count|\n",
            "+------------+------+\n",
            "|         264|159760|\n",
            "|         265|  3871|\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgHlZCHhAxlG",
        "outputId": "b29f5ead-1fa9-4224-96f5-0f1b112c03ad"
      },
      "source": [
        "# and for dropoff\n",
        "spark.sql(\"\"\"\n",
        "            SELECT DOLocationID, count(DOLocationID) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE DOLocationID = \"264\"\n",
        "            OR DOLocationID = \"265\"\n",
        "            GROUP by DOLocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|DOLocationID| count|\n",
            "+------------+------+\n",
            "|         264|149094|\n",
            "|         265| 16817|\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svSnDRJ1AxlH",
        "outputId": "1d832d86-7150-4720-e4e6-016ac27513ce"
      },
      "source": [
        "# count where pu location was 264 unknown as was dropoff\n",
        "spark.sql(\"\"\"\n",
        "            SELECT DOLocationID, count(DOLocationID) AS count\n",
        "            FROM data_init_view\n",
        "            WHERE PULocationID = \"264\"\n",
        "            AND DOLocationID = \"264\"\n",
        "            GROUP by DOLocationID\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|DOLocationID| count|\n",
            "+------------+------+\n",
            "|         264|138614|\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO26yjBrAxlI",
        "outputId": "06b56108-f0bd-46e7-b200-b2fe685e9e51"
      },
      "source": [
        "# where pickup was other unknown but dropoff was not\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE PULocationID = \"265\"\n",
        "            AND DOLocationID != \"264\"\n",
        "            AND DOLocationID != \"265\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "811"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcSYaqazAxlJ",
        "outputId": "49ce2474-2944-4bac-f85f-9d4b8942e81f"
      },
      "source": [
        "# where dropoff was  unknown but pickup was not\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE DOLocationID = \"265\"\n",
        "            AND PULocationID != \"264\"\n",
        "            AND PULocationID != \"265\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13316"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dc84LwhPAxlK",
        "outputId": "9d84e919-ee07-402d-a563-5868223efa90"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE DOLocationID = \"264\"\n",
        "            AND PULocationID != \"264\"\n",
        "            AND PULocationID != \"265\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10454"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzQzMQmzAxlL",
        "outputId": "9a5bbe71-fc91-4fc6-842c-58740eba9fa6"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_init_view\n",
        "            WHERE DOLocationID = \"265\"\n",
        "            AND PULocationID = \"265\"\n",
        "        \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3034"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQj0bxHTAxlM",
        "outputId": "90ca6d0f-4140-4585-ed38-4bfaeb555269"
      },
      "source": [
        "data.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: string (nullable = true)\n",
            " |-- pickup_datetime: string (nullable = true)\n",
            " |-- dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: string (nullable = true)\n",
            " |-- trip_distance: string (nullable = true)\n",
            " |-- RatecodeID: string (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: string (nullable = true)\n",
            " |-- DOLocationID: string (nullable = true)\n",
            " |-- payment_type: string (nullable = true)\n",
            " |-- fare_amount: string (nullable = true)\n",
            " |-- extra: string (nullable = true)\n",
            " |-- mta_tax: string (nullable = true)\n",
            " |-- tip_amount: string (nullable = true)\n",
            " |-- tolls_amount: string (nullable = true)\n",
            " |-- improvement_surcharge: string (nullable = true)\n",
            " |-- total_amount: string (nullable = true)\n",
            " |-- congestion_surcharge: string (nullable = true)\n",
            " |-- trip_type: string (nullable = false)\n",
            " |-- ehail_fee: string (nullable = false)\n",
            " |-- colour: string (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOXtYkSpAxlN"
      },
      "source": [
        "spark.catalog.dropTempView(\"data_init_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxj_VqDgAxlO"
      },
      "source": [
        "## Remove duplicate rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIVgHlf5AxlO"
      },
      "source": [
        "dataunique = data.distinct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVwBHKPSAxlP",
        "outputId": "9566f98a-d8e8-48f1-c512-b53482e07381"
      },
      "source": [
        "dataU = dataunique\n",
        "dataU.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7667792"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWqdcTS8AxlQ"
      },
      "source": [
        "## Initial Cleaning\n",
        "Duplicates?\n",
        "    - Run Distinct\n",
        "### Outcomes from Initial EDA\n",
        "1. Drop ehail_fee\n",
        "2. Drop ratecode=99\n",
        "3. Convert store_and_fwd_flag to bool\n",
        "4. Drop bad dates\n",
        "    - Low pickup_datetime<2019-01-01 00:00:00\n",
        "    - High pickup_datetime>2019-05-31 23:59:59\n",
        "    - Low dropoff_datetime<2019-01-01 00:00:00\n",
        "    - High dropoff_datetime>2019-05-31 23:59:59\n",
        "### Datatypes \n",
        "  - Initially all Strings "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmP6e0DUAxlQ"
      },
      "source": [
        "dataU.createOrReplaceTempView(\"data_u_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r00X3jMjAxlR",
        "outputId": "8ecac09f-2c29-42a5-eb53-f2c891e04cb9"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW clean AS (\n",
        "                SELECT *\n",
        "                FROM data_u_view\n",
        "                WHERE RatecodeID != \"99\"\n",
        "                AND trip_type IS NOT NULL\n",
        "                AND PULocationID != \"265\"\n",
        "                AND pickup_datetime BETWEEN \"2019-01-01 00:00:00\" AND \"2019-01-31 23:59:59\"\n",
        "                AND dropoff_datetime BETWEEN \"2019-01-01 00:00:00\" AND \"2019-01-02 23:59:59\"\n",
        "            )\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7PK7IaIAxlS",
        "outputId": "b57a44df-3bbd-4980-d530-54cfeca17136"
      },
      "source": [
        "spark.sql(\"\"\"       \n",
        "            CREATE OR REPLACE TEMP VIEW clean2 AS (\n",
        "            SELECT VendorID, \n",
        "                pickup_datetime,\n",
        "                dropoff_datetime,\n",
        "                passenger_count,\n",
        "                trip_distance,\n",
        "                RatecodeID,\n",
        "                PULocationID,\n",
        "                DOLocationID,\n",
        "                payment_type,\n",
        "                fare_amount,\n",
        "                extra,\n",
        "                mta_tax,\n",
        "                tip_amount,\n",
        "                tolls_amount,\n",
        "                improvement_surcharge,\n",
        "                total_amount,\n",
        "            CASE WHEN store_and_fwd_flag = \"Y\" THEN \"1\"\n",
        "            ELSE \"0\"\n",
        "            END AS store_and_fwd_flag,\n",
        "            CASE WHEN trip_type = \"1\" THEN \"0\"\n",
        "            ELSE \"0\"\n",
        "            END AS dispatched,\n",
        "            CASE WHEN colour = \"yellow\" THEN \"0\"\n",
        "            ELSE \"0\"\n",
        "            END AS colour\n",
        "            FROM clean\n",
        "            )\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKvZQpyFAxlT"
      },
      "source": [
        "dataC = spark.sql(\"SELECT * FROM clean2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9R2LZlXEAxla",
        "outputId": "fd4a86d0-5b38-45af-c2cf-1f526c324d22"
      },
      "source": [
        "dataC.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'pickup_datetime',\n",
              " 'dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'store_and_fwd_flag',\n",
              " 'dispatched',\n",
              " 'colour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mF8OKhWCAxlb"
      },
      "source": [
        "## Cleck all columns for NA/Null\n",
        "- NA\n",
        "- N/A\n",
        "- NAN\n",
        "- NULL\n",
        "- NIL\n",
        "- \" \""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwTZrjRBAxlb",
        "outputId": "f4ee196f-ce49-4be8-e935-126a2417c3c5"
      },
      "source": [
        "# common na strings as list\n",
        "commonNA = [\"NA\", \"N/A\", \"NAN\", \"NIL\", \"NULL\", \" \"]\n",
        "\n",
        "# columns from dataset\n",
        "columns = dataC.columns\n",
        "\n",
        "# blank output list\n",
        "anil = []\n",
        "\n",
        "# write a sql query string that converts any in the common na list in all columns in columns list to null using SQL NULLIF\n",
        "# first by na string\n",
        "for nval in commonNA:\n",
        "    scol = []\n",
        "    for col in columns:\n",
        "        # constrcuts string for each column\n",
        "        nif = f\"NULLIF(UPPER({col}), UPPER('{nval}')) AS {col}\"\n",
        "        scol.append(nif)\n",
        "    scol = \", \".join(scol)\n",
        "    # puts all null strings into select statement\n",
        "    scol = f\"SELECT {scol} FROM clean2\"\n",
        "    anil.append(scol)\n",
        "\n",
        "# check output\n",
        "anil"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"SELECT NULLIF(UPPER(VendorID), UPPER('NA')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER('NA')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER('NA')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER('NA')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER('NA')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER('NA')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER('NA')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER('NA')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER('NA')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER('NA')) AS fare_amount, NULLIF(UPPER(extra), UPPER('NA')) AS extra, NULLIF(UPPER(mta_tax), UPPER('NA')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER('NA')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER('NA')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER('NA')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER('NA')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER('NA')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER('NA')) AS dispatched, NULLIF(UPPER(colour), UPPER('NA')) AS colour FROM clean2\",\n",
              " \"SELECT NULLIF(UPPER(VendorID), UPPER('N/A')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER('N/A')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER('N/A')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER('N/A')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER('N/A')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER('N/A')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER('N/A')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER('N/A')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER('N/A')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER('N/A')) AS fare_amount, NULLIF(UPPER(extra), UPPER('N/A')) AS extra, NULLIF(UPPER(mta_tax), UPPER('N/A')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER('N/A')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER('N/A')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER('N/A')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER('N/A')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER('N/A')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER('N/A')) AS dispatched, NULLIF(UPPER(colour), UPPER('N/A')) AS colour FROM clean2\",\n",
              " \"SELECT NULLIF(UPPER(VendorID), UPPER('NAN')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER('NAN')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER('NAN')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER('NAN')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER('NAN')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER('NAN')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER('NAN')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER('NAN')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER('NAN')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER('NAN')) AS fare_amount, NULLIF(UPPER(extra), UPPER('NAN')) AS extra, NULLIF(UPPER(mta_tax), UPPER('NAN')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER('NAN')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER('NAN')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER('NAN')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER('NAN')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER('NAN')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER('NAN')) AS dispatched, NULLIF(UPPER(colour), UPPER('NAN')) AS colour FROM clean2\",\n",
              " \"SELECT NULLIF(UPPER(VendorID), UPPER('NIL')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER('NIL')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER('NIL')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER('NIL')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER('NIL')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER('NIL')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER('NIL')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER('NIL')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER('NIL')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER('NIL')) AS fare_amount, NULLIF(UPPER(extra), UPPER('NIL')) AS extra, NULLIF(UPPER(mta_tax), UPPER('NIL')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER('NIL')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER('NIL')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER('NIL')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER('NIL')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER('NIL')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER('NIL')) AS dispatched, NULLIF(UPPER(colour), UPPER('NIL')) AS colour FROM clean2\",\n",
              " \"SELECT NULLIF(UPPER(VendorID), UPPER('NULL')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER('NULL')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER('NULL')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER('NULL')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER('NULL')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER('NULL')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER('NULL')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER('NULL')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER('NULL')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER('NULL')) AS fare_amount, NULLIF(UPPER(extra), UPPER('NULL')) AS extra, NULLIF(UPPER(mta_tax), UPPER('NULL')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER('NULL')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER('NULL')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER('NULL')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER('NULL')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER('NULL')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER('NULL')) AS dispatched, NULLIF(UPPER(colour), UPPER('NULL')) AS colour FROM clean2\",\n",
              " \"SELECT NULLIF(UPPER(VendorID), UPPER(' ')) AS VendorID, NULLIF(UPPER(pickup_datetime), UPPER(' ')) AS pickup_datetime, NULLIF(UPPER(dropoff_datetime), UPPER(' ')) AS dropoff_datetime, NULLIF(UPPER(passenger_count), UPPER(' ')) AS passenger_count, NULLIF(UPPER(trip_distance), UPPER(' ')) AS trip_distance, NULLIF(UPPER(RatecodeID), UPPER(' ')) AS RatecodeID, NULLIF(UPPER(PULocationID), UPPER(' ')) AS PULocationID, NULLIF(UPPER(DOLocationID), UPPER(' ')) AS DOLocationID, NULLIF(UPPER(payment_type), UPPER(' ')) AS payment_type, NULLIF(UPPER(fare_amount), UPPER(' ')) AS fare_amount, NULLIF(UPPER(extra), UPPER(' ')) AS extra, NULLIF(UPPER(mta_tax), UPPER(' ')) AS mta_tax, NULLIF(UPPER(tip_amount), UPPER(' ')) AS tip_amount, NULLIF(UPPER(tolls_amount), UPPER(' ')) AS tolls_amount, NULLIF(UPPER(improvement_surcharge), UPPER(' ')) AS improvement_surcharge, NULLIF(UPPER(total_amount), UPPER(' ')) AS total_amount, NULLIF(UPPER(store_and_fwd_flag), UPPER(' ')) AS store_and_fwd_flag, NULLIF(UPPER(dispatched), UPPER(' ')) AS dispatched, NULLIF(UPPER(colour), UPPER(' ')) AS colour FROM clean2\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtQXrKVJAxlc"
      },
      "source": [
        "# create a query for each na string, replaceing view each update\n",
        "for query in anil:\n",
        "    fq = f\"CREATE OR REPLACE TEMP VIEW clean2 AS ({query})\"\n",
        "    spark.sql(fq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuOrFELCAxlc"
      },
      "source": [
        "# write to df\n",
        "dataC = spark.sql(\"SELECT * FROM clean2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSxT4Z9OAxld",
        "outputId": "4b9430c5-456f-4946-eb4f-87c76a4ee61b"
      },
      "source": [
        "dataC.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'pickup_datetime',\n",
              " 'dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'store_and_fwd_flag',\n",
              " 'dispatched',\n",
              " 'colour']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woC7y9jvAxle"
      },
      "source": [
        "dataC3 = dataC"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5WbpoAOAxle"
      },
      "source": [
        "# dataC3 = spark.read.parquet(\"./data/clean2.parquet\")\n",
        "dataC3.createOrReplaceTempView(\"data_c3_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUf-MMsOAxlf"
      },
      "source": [
        "## Trip Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGksmX2gAxlf",
        "outputId": "b60a4ead-0567-4277-ada8-bf088290e261"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW trip_view AS (\n",
        "            SELECT *, datediff(dropoff_datetime, pickup_datetime) as tripdays\n",
        "            FROM data_c3_view\n",
        "            )\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg61cRLmAxlh"
      },
      "source": [
        "tripClean = spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM trip_view\n",
        "            WHERE tripdays <= 1\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWRCosgJAxli"
      },
      "source": [
        "dataTC = tripClean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XBEnaV3Axlk"
      },
      "source": [
        "#dataTC = dataTC.repartition(180) # increase from 36 due to shuffle spill\n",
        "dataTC.createOrReplaceTempView(\"data_TC_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7fsWFuvAxlk",
        "outputId": "8105d4de-b38f-40b4-be1b-0e8a99fe1d23"
      },
      "source": [
        "# count number of potential refunds\n",
        "# use absolute to match negative totals with positives\n",
        "spark.sql(\"\"\"\n",
        "            SELECT pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, ABS(total_amount) AS fare, count(*) AS count\n",
        "            FROM data_TC_view\n",
        "            GROUP BY pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, fare\n",
        "            HAVING count > 1\n",
        "            ORDER BY count DESC\n",
        "            \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "420"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1MotNYNAxll",
        "outputId": "051620d7-2838-4631-8b2a-c6c0a97f8ae8"
      },
      "source": [
        "# show examples\n",
        "spark.sql(\"\"\"\n",
        "            SELECT pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, ABS(total_amount) AS fare, count(*) AS count\n",
        "            FROM data_TC_view\n",
        "            GROUP BY pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, fare\n",
        "            HAVING count > 1\n",
        "            ORDER BY count DESC\n",
        "            \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+-------------------+------------+------------+----+-----+\n",
            "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|fare|count|\n",
            "+-------------------+-------------------+------------+------------+----+-----+\n",
            "|2019-01-02 12:51:51|2019-01-02 12:52:05|          93|          93| 3.8|    2|\n",
            "|2019-01-01 18:38:10|2019-01-01 18:39:35|          75|          75|52.8|    2|\n",
            "|2019-01-02 13:21:02|2019-01-02 13:24:38|         236|         239| 5.3|    2|\n",
            "|2019-01-02 15:49:13|2019-01-02 15:55:43|         237|         238| 7.8|    2|\n",
            "|2019-01-01 00:33:02|2019-01-01 00:36:38|         166|         151| 6.3|    2|\n",
            "|2019-01-01 16:18:12|2019-01-01 16:30:03|         144|         158|10.8|    2|\n",
            "|2019-01-01 14:48:32|2019-01-01 14:52:57|         209|         261| 5.3|    2|\n",
            "|2019-01-01 04:50:18|2019-01-01 04:50:25|         264|         235|80.3|    2|\n",
            "|2019-01-01 18:25:16|2019-01-01 18:25:24|         142|          43|52.8|    2|\n",
            "|2019-01-02 17:32:52|2019-01-02 17:38:31|         231|          45| 7.8|    2|\n",
            "|2019-01-01 05:13:22|2019-01-01 05:15:26|          79|         113| 4.8|    2|\n",
            "|2019-01-01 04:23:42|2019-01-01 04:26:52|          75|          75| 5.8|    2|\n",
            "|2019-01-01 15:43:08|2019-01-01 15:44:43|         162|         170| 4.3|    2|\n",
            "|2019-01-02 20:25:48|2019-01-02 20:30:17|         211|         209| 6.3|    2|\n",
            "|2019-01-01 12:35:38|2019-01-01 12:36:27|         236|         236| 3.8|    2|\n",
            "|2019-01-02 12:29:18|2019-01-02 12:33:55|         238|         238| 5.3|    2|\n",
            "|2019-01-01 15:46:07|2019-01-01 15:50:44|         186|         234| 6.3|    2|\n",
            "|2019-01-01 14:08:31|2019-01-01 14:08:39|         237|          43| 3.3|    2|\n",
            "|2019-01-02 22:51:18|2019-01-02 22:52:06|         138|         138| 3.8|    2|\n",
            "|2019-01-01 12:18:29|2019-01-01 12:19:35|         211|         211| 3.8|    2|\n",
            "+-------------------+-------------------+------------+------------+----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5jZNofYAxlm",
        "outputId": "048cf176-7f1b-4601-d90d-396de49e5a4e"
      },
      "source": [
        "# create view redistributing data to reduce later shuffle\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW data_TC_redis AS\n",
        "            SELECT *\n",
        "            FROM data_TC_view\n",
        "            DISTRIBUTE BY PULocationID\n",
        "            SORT BY DOLocationID, pickup_datetime, dropoff_datetime\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKc2EF3cAxln",
        "outputId": "a6917eff-2b2f-4901-b456-a122921feeb4"
      },
      "source": [
        "# create view of duplicates / refunds\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW refunds AS\n",
        "            SELECT pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, ABS(total_amount) AS fare, count(*) AS count\n",
        "            FROM data_TC_view\n",
        "            GROUP BY PULocationID, DOLocationID, pickup_datetime, dropoff_datetime, fare\n",
        "            HAVING count > 1\n",
        "            DISTRIBUTE BY PULocationID\n",
        "            SORT BY DOLocationID, pickup_datetime, dropoff_datetime\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_mMkxYDAxln"
      },
      "source": [
        "# create refund flag, when multiple flag is 1\n",
        "refunds = spark.sql(\"\"\"\n",
        "            SELECT data_tc_redis.*, CASE WHEN refunds.count = \"2\" THEN \"1\"\n",
        "                                    ELSE \"0\"\n",
        "                                    END AS refunded_flag\n",
        "            FROM data_tc_redis\n",
        "            LEFT JOIN refunds\n",
        "            ON data_tc_redis.PULocationID = refunds.PULocationID\n",
        "            AND data_tc_redis.DOLocationID = refunds.DOLocationID\n",
        "            AND data_tc_redis.pickup_datetime = refunds.pickup_datetime\n",
        "            AND data_tc_redis.dropoff_datetime = refunds.dropoff_datetime\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q45A5ff9Axlo"
      },
      "source": [
        "dataR = refunds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZsIjA8zAxlp"
      },
      "source": [
        "# dataR = spark.read.parquet(\"./data/refundFlagged.parquet\")\n",
        "dataR.createOrReplaceTempView(\"data_R_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diJ_Yo-2Axlq",
        "outputId": "c7ab6a4a-f85b-48b5-eaf3-fb8f36bb7a69"
      },
      "source": [
        "# check number of \"refunds\"\n",
        "spark.sql(\"\"\"\n",
        "            SELECT refunded_flag, count(refunded_flag)\n",
        "            FROM data_R_view\n",
        "            GROUP by refunded_flag\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------+--------------------+\n",
            "|refunded_flag|count(refunded_flag)|\n",
            "+-------------+--------------------+\n",
            "|            0|              384221|\n",
            "|            1|                 840|\n",
            "+-------------+--------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpBV-zJ2Axlr",
        "outputId": "9d051a95-7d3a-44f9-8e32-d4f729e18425"
      },
      "source": [
        "# inspect examples\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_R_view\n",
        "            WHERE refunded_flag = 1\n",
        "            \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+----------+------+--------+-------------+\n",
            "|VendorID|    pickup_datetime|   dropoff_datetime|passenger_count|trip_distance|RatecodeID|PULocationID|DOLocationID|payment_type|fare_amount|extra|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|store_and_fwd_flag|dispatched|colour|tripdays|refunded_flag|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+----------+------+--------+-------------+\n",
            "|       2|2019-01-02 19:40:58|2019-01-02 19:44:44|              1|          .51|         1|         237|         141|           2|        4.5|    1|    0.5|         0|           1|                  0.3|         7.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 19:40:58|2019-01-02 19:44:44|              1|          .51|         1|         237|         141|           3|       -4.5|   -1|   -0.5|         0|          -1|                 -0.3|        -7.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 11:21:20|2019-01-02 11:23:36|              1|          .35|         1|         161|         161|           2|        3.5|    0|    0.5|         0|           0|                  0.3|         4.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 11:21:20|2019-01-02 11:23:36|              1|          .35|         1|         161|         161|           3|       -3.5|    0|   -0.5|         0|           0|                 -0.3|        -4.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-01 03:03:44|2019-01-01 03:04:15|              1|          .02|         1|         226|         226|           2|        2.5|  0.5|    0.5|         0|           0|                  0.3|         3.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-01 03:03:44|2019-01-01 03:04:15|              1|          .02|         1|         226|         226|           4|       -2.5| -0.5|   -0.5|         0|           0|                 -0.3|        -3.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 12:29:18|2019-01-02 12:33:55|              2|          .03|         1|         238|         238|           4|       -4.5|    0|   -0.5|         0|           0|                 -0.3|        -5.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 12:29:18|2019-01-02 12:33:55|              2|          .03|         1|         238|         238|           2|        4.5|    0|    0.5|         0|           0|                  0.3|         5.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 18:48:28|2019-01-02 18:51:30|              1|          .00|         1|           7|         193|           2|        2.5|    1|    0.5|         0|           0|                  0.3|         4.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 18:48:28|2019-01-02 18:51:30|              1|          .00|         1|           7|         193|           3|       -2.5|   -1|   -0.5|         0|           0|                 -0.3|        -4.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 08:24:02|2019-01-02 08:24:11|              1|          .00|         3|         162|         162|           4|        -20|    0|      0|         0|           0|                 -0.3|       -20.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 08:24:02|2019-01-02 08:24:11|              1|          .00|         3|         162|         162|           2|         20|    0|      0|         0|           0|                  0.3|        20.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 07:26:03|2019-01-02 08:05:47|              1|        11.86|         1|         186|          14|           2|        -40|    0|   -0.5|         0|           0|                 -0.3|       -40.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 07:26:03|2019-01-02 08:05:47|              1|        11.86|         1|         186|          14|           2|         40|    0|    0.5|         0|           0|                  0.3|        40.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 16:11:12|2019-01-02 16:16:30|              1|          .97|         1|         161|         234|           2|        5.5|    1|    0.5|         0|           0|                  0.3|         7.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 16:11:12|2019-01-02 16:16:30|              1|          .97|         1|         161|         234|           4|       -5.5|   -1|   -0.5|         0|           0|                 -0.3|        -7.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-01 00:51:47|2019-01-01 00:53:44|              1|          .36|         1|         186|         186|           2|        3.5|  0.5|    0.5|         0|           0|                  0.3|         4.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-01 00:51:47|2019-01-01 00:53:44|              1|          .36|         1|         186|         186|           4|       -3.5| -0.5|   -0.5|         0|           0|                 -0.3|        -4.8|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 14:53:24|2019-01-02 14:55:19|              1|          .14|         1|          43|          43|           4|       -3.5|    0|   -0.5|         0|           0|                 -0.3|        -4.3|                 0|         0|     0|       0|            1|\n",
            "|       2|2019-01-02 14:53:24|2019-01-02 14:55:19|              1|          .14|         1|          43|          43|           2|        3.5|    0|    0.5|         0|           0|                  0.3|         4.3|                 0|         0|     0|       0|            1|\n",
            "+--------+-------------------+-------------------+---------------+-------------+----------+------------+------------+------------+-----------+-----+-------+----------+------------+---------------------+------------+------------------+----------+------+--------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAsQtQXaAxls",
        "outputId": "92833517-6ace-40d3-855a-68d75d77e9fb"
      },
      "source": [
        "# count where total amount is 0\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM data_R_view\n",
        "            WHERE refunded_flag = 1\n",
        "            AND NOT total_amount < \"0\"\n",
        "            AND NOT total_amount > \"0\"           \n",
        "            \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Io-k0jAxlt"
      },
      "source": [
        "# some equal fares so need to investigate\n",
        "equalfares = spark.sql(\"\"\"\n",
        "                        SELECT pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, total_amount, count(*) AS count\n",
        "                        FROM data_R_view\n",
        "                        GROUP BY PULocationID, DOLocationID, pickup_datetime, dropoff_datetime, total_amount\n",
        "                        HAVING count > 1\n",
        "                        \"\"\")\n",
        "# equalfares.cache()\n",
        "equalfares.createOrReplaceTempView(\"dups_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1c8uYNOAxlu",
        "outputId": "25762ec8-87f3-4657-ac60-6a3df29ba21a"
      },
      "source": [
        "equalfares.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U76UseEAxlu"
      },
      "source": [
        "# use left join exlusive to remove furhter duplicates\n",
        "removedups = spark.sql(\"\"\"\n",
        "            SELECT data_R_view.*\n",
        "            FROM data_R_view\n",
        "            LEFT JOIN dups_view\n",
        "            ON data_R_view.PULocationID = dups_view.PULocationID\n",
        "            AND data_R_view.DOLocationID = dups_view.DOLocationID\n",
        "            AND data_R_view.pickup_datetime = dups_view.pickup_datetime\n",
        "            AND data_R_view.dropoff_datetime = dups_view.dropoff_datetime\n",
        "            WHERE dups_view.PULocationID IS NULL\n",
        "            AND dups_view.DOLocationID IS NULL\n",
        "            AND dups_view.pickup_datetime IS NULL\n",
        "            AND dups_view.dropoff_datetime IS NULL\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYNaoZ2QAxlx"
      },
      "source": [
        "datarfd = removedups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Qx963qAxlx"
      },
      "source": [
        "datarfd.createOrReplaceTempView(\"rem_dups_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP8hPbDzAxly",
        "outputId": "d1d3dc1e-ceac-4fe0-a362-3eb53364129f"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, total_amount, count(*) AS count\n",
        "            FROM rem_dups_view\n",
        "            GROUP BY PULocationID, DOLocationID, pickup_datetime, dropoff_datetime, total_amount\n",
        "            HAVING count > 1\n",
        "            \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------+----------------+------------+------------+------------+-----+\n",
            "|pickup_datetime|dropoff_datetime|PULocationID|DOLocationID|total_amount|count|\n",
            "+---------------+----------------+------------+------------+------------+-----+\n",
            "+---------------+----------------+------------+------------+------------+-----+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBqyEuVqAxlz"
      },
      "source": [
        "removeRefund = spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM rem_dups_view\n",
        "            WHERE NOT (refunded_flag = \"1\" AND total_amount < \"0\")\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dAqJbkxAxl0",
        "outputId": "fd124dbc-db9f-407b-fb20-2ccb6019352b"
      },
      "source": [
        "# check impact\n",
        "removeRefund.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384641"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryZbO5sBAxl0"
      },
      "source": [
        "# datarfd = spark.read.parquet(\"./data/refunds-cleaned.parquet\")\n",
        "datarfd = removeRefund\n",
        "datarfd.createOrReplaceTempView(\"ref_clean_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBzfozm2Axl1",
        "outputId": "96d6226e-d025-4b79-b0be-dbd816c9206d"
      },
      "source": [
        "# extra\n",
        "spark.sql(\"\"\"\n",
        "            SELECT extra, count(extra) AS count\n",
        "            FROM ref_clean_view\n",
        "            GROUP by extra\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|extra| count|\n",
            "+-----+------+\n",
            "|    0|204848|\n",
            "|  0.5|126463|\n",
            "|    1| 50785|\n",
            "|  4.5|  2486|\n",
            "| -0.5|    12|\n",
            "|  2.5|    11|\n",
            "|  0.8|    10|\n",
            "| 17.5|     9|\n",
            "|    3|     5|\n",
            "|  1.3|     3|\n",
            "|  1.8|     2|\n",
            "| 18.5|     2|\n",
            "|   -1|     1|\n",
            "|   18|     1|\n",
            "|  3.5|     1|\n",
            "|  5.3|     1|\n",
            "| -4.5|     1|\n",
            "+-----+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XiH_-OfAxl1",
        "outputId": "89c301df-a5e3-4ea4-99f3-e089ce8758fc"
      },
      "source": [
        "# mta_tax \n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            SELECT mta_tax, count(mta_tax) AS count\n",
        "            FROM ref_clean_view\n",
        "            GROUP by mta_tax\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+------+\n",
            "|mta_tax| count|\n",
            "+-------+------+\n",
            "|    0.5|382200|\n",
            "|      0|  2417|\n",
            "|   -0.5|    24|\n",
            "+-------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCdBugiFAxl2",
        "outputId": "97b880cf-b830-412d-d287-e025860f4433"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT improvement_surcharge, count(improvement_surcharge) AS count\n",
        "            FROM ref_clean_view\n",
        "            GROUP by improvement_surcharge\n",
        "            ORDER BY count DESC\n",
        "        \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+------+\n",
            "|improvement_surcharge| count|\n",
            "+---------------------+------+\n",
            "|                  0.3|384455|\n",
            "|                    0|   160|\n",
            "|                 -0.3|    26|\n",
            "+---------------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCRtbsMMAxl3",
        "outputId": "da38f572-1a3b-4453-8730-084bb82fa4a5"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW rem_one AS\n",
        "            SELECT *\n",
        "            FROM ref_clean_view\n",
        "            WHERE mta_tax = \"0.5\"\n",
        "            OR mta_tax = \"0\"\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VVVN6wIAxl3",
        "outputId": "cd94f121-fdb0-4836-ad93-a0877aa7b90b"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW rem_two AS\n",
        "            SELECT *\n",
        "            FROM rem_one\n",
        "            WHERE improvement_surcharge = \"0.3\"\n",
        "            OR improvement_surcharge = \"0\"\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hie3Gov-Axl4"
      },
      "source": [
        "cols = spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM rem_two\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKsa3B3_Axl6",
        "outputId": "930b6155-2644-417b-e8e2-306b72e32306"
      },
      "source": [
        "cols.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['VendorID',\n",
              " 'pickup_datetime',\n",
              " 'dropoff_datetime',\n",
              " 'passenger_count',\n",
              " 'trip_distance',\n",
              " 'RatecodeID',\n",
              " 'PULocationID',\n",
              " 'DOLocationID',\n",
              " 'payment_type',\n",
              " 'fare_amount',\n",
              " 'extra',\n",
              " 'mta_tax',\n",
              " 'tip_amount',\n",
              " 'tolls_amount',\n",
              " 'improvement_surcharge',\n",
              " 'total_amount',\n",
              " 'store_and_fwd_flag',\n",
              " 'dispatched',\n",
              " 'colour',\n",
              " 'tripdays',\n",
              " 'refunded_flag']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G9l5FEAAxl6",
        "outputId": "bd9fc0f5-185a-4bd9-cb4d-eb1b30c3d0fa"
      },
      "source": [
        "cols.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: string (nullable = true)\n",
            " |-- pickup_datetime: string (nullable = true)\n",
            " |-- dropoff_datetime: string (nullable = true)\n",
            " |-- passenger_count: string (nullable = true)\n",
            " |-- trip_distance: string (nullable = true)\n",
            " |-- RatecodeID: string (nullable = true)\n",
            " |-- PULocationID: string (nullable = true)\n",
            " |-- DOLocationID: string (nullable = true)\n",
            " |-- payment_type: string (nullable = true)\n",
            " |-- fare_amount: string (nullable = true)\n",
            " |-- extra: string (nullable = true)\n",
            " |-- mta_tax: string (nullable = true)\n",
            " |-- tip_amount: string (nullable = true)\n",
            " |-- tolls_amount: string (nullable = true)\n",
            " |-- improvement_surcharge: string (nullable = true)\n",
            " |-- total_amount: string (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- dispatched: string (nullable = true)\n",
            " |-- colour: string (nullable = true)\n",
            " |-- tripdays: integer (nullable = true)\n",
            " |-- refunded_flag: string (nullable = false)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WT1Iit57Axl7"
      },
      "source": [
        "## convert mta_tax and impreovement_surchage to bools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8hevArQAxl7",
        "outputId": "fee5ce7d-ed89-4de8-d19a-f3f5a6966a39"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW clean_one AS\n",
        "            SELECT VendorID,\n",
        "                    pickup_datetime,\n",
        "                    dropoff_datetime,\n",
        "                    passenger_count,\n",
        "                    trip_distance,\n",
        "                    RatecodeID,\n",
        "                    PULocationID,\n",
        "                    DOLocationID,\n",
        "                    payment_type,\n",
        "                    fare_amount,\n",
        "                    extra,\n",
        "                    tip_amount,\n",
        "                    tolls_amount,\n",
        "                    total_amount,\n",
        "                    store_and_fwd_flag,\n",
        "                    dispatched,\n",
        "                    colour,\n",
        "                    tripdays,\n",
        "                    refunded_flag,\n",
        "                    CASE WHEN mta_tax = \"0.5\" THEN \"1\"\n",
        "                    ELSE \"0\"\n",
        "                    END AS mta_tax,\n",
        "                    CASE WHEN improvement_surcharge = \"0.3\" THEN \"1\"\n",
        "                    ELSE \"0\"\n",
        "                    END AS improvement_surcharge\n",
        "            FROM rem_two\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qNef8rXAxl8",
        "outputId": "47fa8c05-0983-44c4-ece0-0208b5700d0c"
      },
      "source": [
        "# cleaner data enable use of smaller impact datatypes\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW clean_two AS\n",
        "            SELECT TINYINT(VendorID),\n",
        "                        TIMESTAMP(pickup_datetime),\n",
        "                        TIMESTAMP(dropoff_datetime),\n",
        "                        TINYINT(passenger_count),\n",
        "                        FLOAT(trip_distance),\n",
        "                        TINYINT(RatecodeID),\n",
        "                        SMALLINT(PULocationID),\n",
        "                        SMALLINT(DOLocationID),\n",
        "                        TINYINT(payment_type),\n",
        "                        FLOAT(fare_amount),\n",
        "                        FLOAT(extra),\n",
        "                        FLOAT(tip_amount),\n",
        "                        FLOAT(tolls_amount),\n",
        "                        FLOAT(total_amount),\n",
        "                        BOOLEAN(store_and_fwd_flag),\n",
        "                        BOOLEAN(dispatched),\n",
        "                        BOOLEAN(colour) AS yellow,\n",
        "                        tripdays,\n",
        "                        BOOLEAN(refunded_flag),\n",
        "                        BOOLEAN(mta_tax),\n",
        "                        BOOLEAN(improvement_surcharge)\n",
        "            FROM clean_one\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp-Hj68FAxl9"
      },
      "source": [
        "out_clean = spark.sql(\"\"\"\n",
        "                            SELECT *\n",
        "                            FROM clean_two\n",
        "                        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PN4SL6sFAxl-"
      },
      "source": [
        "# datainitclean = spark.read.parquet(\"./data/out_init_clean.parquet\")\n",
        "datainitclean = out_clean\n",
        "datainitclean.createOrReplaceTempView(\"init_clean_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu_xKn2JAxl-",
        "outputId": "a3b58b3e-ee1f-42f2-c7f4-9d81b12a07cb"
      },
      "source": [
        "# need to convert floats to decimals for arithmetic\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW ic_two_view AS\n",
        "            SELECT VendorID,\n",
        "                    pickup_datetime,\n",
        "                    dropoff_datetime,\n",
        "                    passenger_count,\n",
        "                    CAST(trip_distance AS DECIMAL(10,3)),\n",
        "                    RatecodeID,\n",
        "                    PULocationID,\n",
        "                    DOLocationID,\n",
        "                    payment_type,\n",
        "                    CAST(fare_amount AS DECIMAL(10,3)),\n",
        "                    CAST(extra AS DECIMAL(10,3)),\n",
        "                    CAST(tip_amount AS DECIMAL(10,3)),\n",
        "                    CAST(tolls_amount AS DECIMAL(10,3)),\n",
        "                    CAST(total_amount AS DECIMAL(10,3)),\n",
        "                    store_and_fwd_flag,\n",
        "                    dispatched,\n",
        "                    yellow,\n",
        "                    tripdays,\n",
        "                    refunded_flag,\n",
        "                    mta_tax,\n",
        "                    improvement_surcharge\n",
        "            FROM init_clean_view\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKaPJH0QAxl_",
        "outputId": "6fc49575-bab3-492b-a4e8-c1e57076bf35"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            SELECT yellow, count(yellow) AS count\n",
        "            FROM ic_two_view\n",
        "            GROUP BY yellow\n",
        "            ORDER BY count DESC\n",
        "            \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|yellow| count|\n",
            "+------+------+\n",
            "| false|384615|\n",
            "+------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDzVaWBBAxmA",
        "outputId": "361a8713-ec6a-408a-d0d5-d1b7db043def"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            WITH calc AS (\n",
        "                WITH conv AS (\n",
        "                    SELECT fare_amount, extra, tip_amount, tolls_amount, total_amount,\n",
        "                        CASE WHEN mta_tax = true THEN 0.5 ELSE 0 END AS tax,\n",
        "                        CASE WHEN improvement_surcharge = true THEN 0.3 ELSE 0 END AS sur\n",
        "                    FROM ic_two_view\n",
        "                )\n",
        "                SELECT CASE WHEN (fare_amount +\n",
        "                    extra +\n",
        "                    tax +\n",
        "                    tip_amount +\n",
        "                    tolls_amount +\n",
        "                    sur ) = total_amount THEN 1\n",
        "                ELSE 0\n",
        "                END AS totals_equal\n",
        "                FROM conv\n",
        "            )\n",
        "            SELECT totals_equal, count(totals_equal) AS count\n",
        "            FROM calc\n",
        "            GROUP BY totals_equal\n",
        "            ORDER BY count DESC\n",
        "            \"\"\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+------+\n",
            "|totals_equal| count|\n",
            "+------------+------+\n",
            "|           1|383613|\n",
            "|           0|  1002|\n",
            "+------------+------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQvZqsPpAxmA",
        "outputId": "4016c46f-0a2d-46af-fa55-fefdf21cb0f9"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW summed AS\n",
        "                WITH conv AS (\n",
        "                    SELECT fare_amount, extra, tip_amount, tolls_amount, total_amount,\n",
        "                        CASE WHEN mta_tax = true THEN 0.5 ELSE 0 END AS tax,\n",
        "                        CASE WHEN improvement_surcharge = true THEN 0.3 ELSE 0 END AS sur\n",
        "                    FROM ic_two_view\n",
        "                )\n",
        "                SELECT *, (fare_amount +\n",
        "                    extra +\n",
        "                    tax +\n",
        "                    tip_amount +\n",
        "                    tolls_amount +\n",
        "                    sur ) AS sum_costs\n",
        "                FROM conv\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFGeL1wEAxmB",
        "outputId": "491728b2-90d5-438e-f719-ae60040cfcb0"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW diffs AS\n",
        "            SELECT *, total_amount - sum_costs AS totals_diff\n",
        "            FROM summed\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hitYJ0LvAxmB",
        "outputId": "85d5cf3f-f1d4-4719-df69-2d4b59c13299"
      },
      "source": [
        "# check schema\n",
        "spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM diffs\n",
        "            WHERE totals_diff > \"0\"\n",
        "            OR totals_diff < \"0\"\n",
        "            \"\"\").printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- fare_amount: decimal(10,3) (nullable = true)\n",
            " |-- extra: decimal(10,3) (nullable = true)\n",
            " |-- tip_amount: decimal(10,3) (nullable = true)\n",
            " |-- tolls_amount: decimal(10,3) (nullable = true)\n",
            " |-- total_amount: decimal(10,3) (nullable = true)\n",
            " |-- tax: decimal(11,1) (nullable = false)\n",
            " |-- sur: decimal(11,1) (nullable = false)\n",
            " |-- sum_costs: decimal(17,3) (nullable = true)\n",
            " |-- totals_diff: decimal(18,3) (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n65kubTUAxmC"
      },
      "source": [
        "# datainitclean = spark.read.parquet(\"./data/out_init_clean.parquet\")\n",
        "datainitclean.createOrReplaceTempView(\"init_clean_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7GWdxr5AxmC",
        "outputId": "251bd0bc-0b17-4f62-b3d7-a6dcb8ab7caf"
      },
      "source": [
        "# need to convert floats to decimals for arithmetic\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW ic_two_view AS\n",
        "            SELECT VendorID,\n",
        "                    pickup_datetime,\n",
        "                    dropoff_datetime,\n",
        "                    passenger_count,\n",
        "                    CAST(trip_distance AS DECIMAL(10,3)),\n",
        "                    RatecodeID,\n",
        "                    PULocationID,\n",
        "                    DOLocationID,\n",
        "                    payment_type,\n",
        "                    CAST(fare_amount AS DECIMAL(10,3)),\n",
        "                    CAST(extra AS DECIMAL(10,3)),\n",
        "                    CAST(tip_amount AS DECIMAL(10,3)),\n",
        "                    CAST(tolls_amount AS DECIMAL(10,3)),\n",
        "                    CAST(total_amount AS DECIMAL(10,3)),\n",
        "                    store_and_fwd_flag,\n",
        "                    dispatched,\n",
        "                    yellow,\n",
        "                    tripdays,\n",
        "                    refunded_flag,\n",
        "                    mta_tax,\n",
        "                    improvement_surcharge\n",
        "            FROM init_clean_view\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kRSvCyyAxmD",
        "outputId": "d9d5daa6-3597-4adb-9b93-a1952aa5f924"
      },
      "source": [
        "# add fee\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW conv AS\n",
        "                    SELECT *,\n",
        "                        CASE WHEN mta_tax = true THEN 0.5 ELSE 0 END AS mta_tax_fee,\n",
        "                        CASE WHEN improvement_surcharge = true THEN 0.3 ELSE 0 END AS surchage_fee\n",
        "                    FROM ic_two_view\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfKo2e37AxmD",
        "outputId": "56a818ea-0112-4ac4-fd81-313679634841"
      },
      "source": [
        "# add sum\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW summed AS\n",
        "                SELECT *, (fare_amount +\n",
        "                    extra +\n",
        "                    mta_tax_fee +\n",
        "                    tip_amount +\n",
        "                    tolls_amount +\n",
        "                    surchage_fee ) AS sum_costs\n",
        "                FROM conv\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4kOtb1TAxmE",
        "outputId": "8f00b8f0-0e79-4b06-913b-fb54b0da5b0d"
      },
      "source": [
        "# add diffs\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW diffs AS\n",
        "            SELECT *, total_amount - sum_costs AS totals_diff\n",
        "            FROM summed\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vctfdsoQAxmF",
        "outputId": "068fc791-38b7-42df-e7fd-43d10a6d1ab8"
      },
      "source": [
        "#add unix timestamp\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW trip_sec_view AS\n",
        "            SELECT *, (unix_timestamp(dropoff_datetime) - unix_timestamp(pickup_datetime)) AS trip_time_sec\n",
        "            FROM diffs\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohln4Wl_AxmI",
        "outputId": "3346ee78-d7ba-4045-805d-a090384e154f"
      },
      "source": [
        "# check impact of where difference is out of range\n",
        "spark.sql(\"\"\"\n",
        "            SELECT totals_diff\n",
        "            FROM trip_sec_view\n",
        "            WHERE NOT (totals_diff = 1.95 OR totals_diff = 0)\n",
        "            \"\"\").count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "116"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNBEMMxAAxmJ",
        "outputId": "45771423-494b-475b-8700-3227d19cdb2e"
      },
      "source": [
        "# relativley low impact, filter as planned\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW clean_2_1_view AS\n",
        "            SELECT *\n",
        "            FROM trip_sec_view\n",
        "            WHERE (totals_diff = 1.95 OR totals_diff = 0)\n",
        "            AND (extra = 0 OR extra = 0.5 OR extra = 1)\n",
        "            AND (trip_distance > 0 AND trip_distance <= 60)\n",
        "            AND (trip_time_sec > 0 AND trip_time_sec <= (120*60))\n",
        "            AND (fare_amount > 0 AND fare_amount <= 260)\n",
        "            AND PULocationID != 264\n",
        "            AND PULocationID != 265 \n",
        "            AND DOLocationID != 264 \n",
        "            AND DOLocationID != 265\n",
        "            AND RatecodeID != 2\n",
        "            AND RatecodeID != 6\n",
        "            AND (tip_amount >= 0 AND tip_amount <= 40)\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vgSQCpCAxmK"
      },
      "source": [
        "# create object from view\n",
        "cleancontinuous = spark.sql(\"\"\"\n",
        "            SELECT *\n",
        "            FROM clean_2_1_view\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V26-vuknAxmK",
        "outputId": "70a67c0a-bf8f-4b15-97b2-d7bd7e80844f"
      },
      "source": [
        "cleancontinuous.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: byte (nullable = true)\n",
            " |-- pickup_datetime: timestamp (nullable = true)\n",
            " |-- dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: byte (nullable = true)\n",
            " |-- trip_distance: decimal(10,3) (nullable = true)\n",
            " |-- RatecodeID: byte (nullable = true)\n",
            " |-- PULocationID: short (nullable = true)\n",
            " |-- DOLocationID: short (nullable = true)\n",
            " |-- payment_type: byte (nullable = true)\n",
            " |-- fare_amount: decimal(10,3) (nullable = true)\n",
            " |-- extra: decimal(10,3) (nullable = true)\n",
            " |-- tip_amount: decimal(10,3) (nullable = true)\n",
            " |-- tolls_amount: decimal(10,3) (nullable = true)\n",
            " |-- total_amount: decimal(10,3) (nullable = true)\n",
            " |-- store_and_fwd_flag: boolean (nullable = true)\n",
            " |-- dispatched: boolean (nullable = true)\n",
            " |-- yellow: boolean (nullable = true)\n",
            " |-- tripdays: integer (nullable = true)\n",
            " |-- refunded_flag: boolean (nullable = true)\n",
            " |-- mta_tax: boolean (nullable = true)\n",
            " |-- improvement_surcharge: boolean (nullable = true)\n",
            " |-- mta_tax_fee: decimal(11,1) (nullable = false)\n",
            " |-- surchage_fee: decimal(11,1) (nullable = false)\n",
            " |-- sum_costs: decimal(17,3) (nullable = true)\n",
            " |-- totals_diff: decimal(18,3) (nullable = true)\n",
            " |-- trip_time_sec: long (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0dYfpNtAxmL",
        "outputId": "bba68718-a169-48b1-ca39-ebc26ea8e214"
      },
      "source": [
        "cleancontinuous.count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "360628"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maF_qr6dAxmM"
      },
      "source": [
        "cleancontinuous.createOrReplaceTempView(\"clean_cont_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAs_78dlAxmN",
        "outputId": "cc2fca9b-cfaf-4fe2-9aa8-1116bc2d9758"
      },
      "source": [
        "# create new flags for taxi size, no passneger, short trip and near two error\n",
        "# calculate time related variables\n",
        "\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW eng_1_view AS\n",
        "            SELECT *,\n",
        "                BOOLEAN(CASE WHEN passenger_count BETWEEN 7 AND 9 THEN true\n",
        "                ELSE false END) AS flag_maxi_taxi,\n",
        "                BOOLEAN(CASE WHEN passenger_count BETWEEN 4 AND 6 THEN true\n",
        "                ELSE false END) AS flag_lg_taxi,\n",
        "                BOOLEAN(CASE WHEN passenger_count = 0 THEN true\n",
        "                ELSE false END) AS flag_no_passenger,\n",
        "                BOOLEAN(CASE WHEN PUlocationID = DOlocationID THEN true\n",
        "                ELSE false END) AS flag_short_trip,\n",
        "                BOOLEAN(CASE WHEN totals_diff = 1.95 THEN true\n",
        "                ELSE false END) AS flag_near_two_error,\n",
        "                CAST((trip_time_sec / 60) AS DECIMAL(20, 6)) AS trip_time_min,\n",
        "                ((trip_time_sec * trip_distance)/2) AS trip_meta,\n",
        "                DATEDIFF(pickup_datetime, \"2017-01-01\") AS PU_day_of_data,\n",
        "                YEAR(pickup_datetime) AS PU_year,\n",
        "                MONTH(pickup_datetime) AS PU_month_of_year,\n",
        "                WEEKOFYEAR(pickup_datetime) AS PU_week_of_year,\n",
        "                DAYOFMONTH(pickup_datetime) AS PU_day_of_month,\n",
        "                DAYOFWEEK(pickup_datetime) AS PU_day_of_week,\n",
        "                HOUR(pickup_datetime) AS PU_hour_of_day,\n",
        "                MINUTE(pickup_datetime) AS PU_min_of_hour\n",
        "            FROM clean_cont_view\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmBwdYc5AxmN",
        "outputId": "efc2f6e6-60a6-455d-e4f4-ee6ed3bb2968"
      },
      "source": [
        "# check structure of time output (0 or 24)\n",
        "spark.sql(\"\"\"\n",
        "            SELECT DISTINCT PU_hour_of_day\n",
        "            FROM eng_1_view\n",
        "            ORDER BY PU_hour_of_day\n",
        "            \"\"\").show(26)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------------+\n",
            "|PU_hour_of_day|\n",
            "+--------------+\n",
            "|             0|\n",
            "|             1|\n",
            "|             2|\n",
            "|             3|\n",
            "|             4|\n",
            "|             5|\n",
            "|             6|\n",
            "|             7|\n",
            "|             8|\n",
            "|             9|\n",
            "|            10|\n",
            "|            11|\n",
            "|            12|\n",
            "|            13|\n",
            "|            14|\n",
            "|            15|\n",
            "|            16|\n",
            "|            17|\n",
            "|            18|\n",
            "|            19|\n",
            "|            20|\n",
            "|            21|\n",
            "|            22|\n",
            "|            23|\n",
            "+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RhzvyzvAxmO",
        "outputId": "9e86868b-33f8-4956-98f3-ad76388747fc"
      },
      "source": [
        "# calculate derived time variables\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW eng_2_view AS\n",
        "            SELECT *,\n",
        "              (trip_time_min / 60) AS trip_time_hour,\n",
        "              CASE WHEN PU_year = 2019 THEN 0\n",
        "              ELSE 1 END AS PU_year_of_data,\n",
        "              (PU_min_of_hour + (PU_hour_of_day * 60)) AS PU_min_of_day\n",
        "            FROM eng_1_view\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6FbJJLmAxmP",
        "outputId": "113eb9d3-9d7b-41ad-879f-9d682b5de142"
      },
      "source": [
        "# further derived time variables and speed\n",
        "spark.sql(\"\"\"\n",
        "            CREATE OR REPLACE TEMP VIEW eng_3_view AS\n",
        "            SELECT *,\n",
        "                (trip_distance / trip_time_hour) AS trip_avg_speed,\n",
        "                (PU_month_of_year + (PU_year_of_data * 12)) AS PU_month_of_data,\n",
        "                (PU_week_of_year + (PU_year_of_data * 52)) AS PU_week_of_data,\n",
        "                (PU_day_of_data - (PU_year_of_data * 365)) AS PU_day_of_year\n",
        "            FROM eng_2_view\n",
        "            \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeNCe-PnAxmQ"
      },
      "source": [
        "firstVarEng = spark.sql(\"\"\"\n",
        "                SELECT *\n",
        "                FROM eng_3_view\n",
        "                \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1nDQdwiAxmQ",
        "outputId": "d6ffd2db-1d97-4f59-8c4f-18cd4d9aaf26"
      },
      "source": [
        "firstVarEng.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: byte (nullable = true)\n",
            " |-- pickup_datetime: timestamp (nullable = true)\n",
            " |-- dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: byte (nullable = true)\n",
            " |-- trip_distance: decimal(10,3) (nullable = true)\n",
            " |-- RatecodeID: byte (nullable = true)\n",
            " |-- PULocationID: short (nullable = true)\n",
            " |-- DOLocationID: short (nullable = true)\n",
            " |-- payment_type: byte (nullable = true)\n",
            " |-- fare_amount: decimal(10,3) (nullable = true)\n",
            " |-- extra: decimal(10,3) (nullable = true)\n",
            " |-- tip_amount: decimal(10,3) (nullable = true)\n",
            " |-- tolls_amount: decimal(10,3) (nullable = true)\n",
            " |-- total_amount: decimal(10,3) (nullable = true)\n",
            " |-- store_and_fwd_flag: boolean (nullable = true)\n",
            " |-- dispatched: boolean (nullable = true)\n",
            " |-- yellow: boolean (nullable = true)\n",
            " |-- tripdays: integer (nullable = true)\n",
            " |-- refunded_flag: boolean (nullable = true)\n",
            " |-- mta_tax: boolean (nullable = true)\n",
            " |-- improvement_surcharge: boolean (nullable = true)\n",
            " |-- mta_tax_fee: decimal(11,1) (nullable = false)\n",
            " |-- surchage_fee: decimal(11,1) (nullable = false)\n",
            " |-- sum_costs: decimal(17,3) (nullable = true)\n",
            " |-- totals_diff: decimal(18,3) (nullable = true)\n",
            " |-- trip_time_sec: long (nullable = true)\n",
            " |-- flag_maxi_taxi: boolean (nullable = false)\n",
            " |-- flag_lg_taxi: boolean (nullable = false)\n",
            " |-- flag_no_passenger: boolean (nullable = false)\n",
            " |-- flag_short_trip: boolean (nullable = false)\n",
            " |-- flag_near_two_error: boolean (nullable = false)\n",
            " |-- trip_time_min: decimal(20,6) (nullable = true)\n",
            " |-- trip_meta: decimal(34,6) (nullable = true)\n",
            " |-- PU_day_of_data: integer (nullable = true)\n",
            " |-- PU_year: integer (nullable = true)\n",
            " |-- PU_month_of_year: integer (nullable = true)\n",
            " |-- PU_week_of_year: integer (nullable = true)\n",
            " |-- PU_day_of_month: integer (nullable = true)\n",
            " |-- PU_day_of_week: integer (nullable = true)\n",
            " |-- PU_hour_of_day: integer (nullable = true)\n",
            " |-- PU_min_of_hour: integer (nullable = true)\n",
            " |-- trip_time_hour: decimal(23,9) (nullable = true)\n",
            " |-- PU_year_of_data: integer (nullable = false)\n",
            " |-- PU_min_of_day: integer (nullable = true)\n",
            " |-- trip_avg_speed: decimal(38,22) (nullable = true)\n",
            " |-- PU_month_of_data: integer (nullable = true)\n",
            " |-- PU_week_of_data: integer (nullable = true)\n",
            " |-- PU_day_of_year: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgrXrFcAAxmR"
      },
      "source": [
        "firstVarEng.createOrReplaceTempView(\"eng_3_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHAavAL0AxmS"
      },
      "source": [
        "firstVarEngCluster = spark.sql(\"\"\"\n",
        "                                SELECT *\n",
        "                                FROM eng_3_view\n",
        "                                CLUSTER BY PUlocationID, DOlocationID\n",
        "                                \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm6peZOBAxmS"
      },
      "source": [
        "firstVarEngCluster.createOrReplaceTempView(\"eng_3_view_cluster\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx9Gagk9AxmS",
        "outputId": "b91cac20-34e7-4930-81a0-767205c424d4"
      },
      "source": [
        "taxizone = spark.read.csv(\"Dataset/taxi+_zone_lookup.csv\", header = True)\n",
        "# minimze partitons of small dataset to reduce shuffle (similar to broadcast)\n",
        "taxizone.repartition(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[LocationID: string, Borough: string, Zone: string, service_zone: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XekaPDfAxmT"
      },
      "source": [
        "taxizone.createOrReplaceTempView(\"taxizone\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZMdaj8DAxmT",
        "outputId": "7d44758d-081d-4a28-c986-ba851a35fdd5"
      },
      "source": [
        "# sort to reduce shuffle\n",
        "spark.sql(\"\"\"\n",
        "        SELECT *\n",
        "        FROM taxizone\n",
        "        WHERE LocationID != 264\n",
        "        AND LocationID != 265\n",
        "        SORT BY LocationID\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[LocationID: string, Borough: string, Zone: string, service_zone: string]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy9eIQ1GAxmU",
        "outputId": "eaa3df0e-9a09-4e3a-a315-db62c422ac1c"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW PUtaxizone AS\n",
        "        SELECT LocationID AS PULocationID, Borough AS PUBorough, Zone AS PUZone, service_zone AS PUServiceZone\n",
        "        FROM taxizone\n",
        "        SORT BY PULocationID\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SM9XMopVAxmV",
        "outputId": "7d3b5700-29c3-4db2-d5f5-3ede4a820912"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW DOtaxizone AS\n",
        "        SELECT LocationID AS DOLocationID, Borough AS DOBorough, Zone AS DOZone, service_zone AS DOServiceZone\n",
        "        FROM taxizone\n",
        "        SORT BY DOLocationID\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcWvF_YUAxmV",
        "outputId": "185921d6-279f-466f-bc7a-1877bc5a2a8a"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW PUjoin AS\n",
        "        SELECT eng_3_view_cluster.*, PUtaxizone.PUBorough, PUtaxizone.PUZone, PUtaxizone.PUServiceZone\n",
        "        FROM eng_3_view_cluster\n",
        "        LEFT JOIN PUtaxizone\n",
        "        ON eng_3_view_cluster.PULocationID = PUtaxizone.PULocationID\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acHlCnLSAxmW",
        "outputId": "20b97dec-8619-472f-a050-5a9b75a34e91"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW DOjoin AS\n",
        "        SELECT PUjoin.*, DOtaxizone.DOBorough, DOtaxizone.DOZone, DOtaxizone.DOServiceZone\n",
        "        FROM PUjoin\n",
        "        LEFT JOIN DOtaxizone\n",
        "        ON PUjoin.DOLocationID = DOtaxizone.DOLocationID\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OMIryVUAxmX"
      },
      "source": [
        "zonejoined = spark.sql(\"\"\"\n",
        "                        SELECT *\n",
        "                        FROM DOjoin\n",
        "                        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USp-Juf5AxmX",
        "outputId": "cddf17ae-7626-4d65-f5f8-8db6971314c1"
      },
      "source": [
        "zonejoined.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: byte (nullable = true)\n",
            " |-- pickup_datetime: timestamp (nullable = true)\n",
            " |-- dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: byte (nullable = true)\n",
            " |-- trip_distance: decimal(10,3) (nullable = true)\n",
            " |-- RatecodeID: byte (nullable = true)\n",
            " |-- PULocationID: short (nullable = true)\n",
            " |-- DOLocationID: short (nullable = true)\n",
            " |-- payment_type: byte (nullable = true)\n",
            " |-- fare_amount: decimal(10,3) (nullable = true)\n",
            " |-- extra: decimal(10,3) (nullable = true)\n",
            " |-- tip_amount: decimal(10,3) (nullable = true)\n",
            " |-- tolls_amount: decimal(10,3) (nullable = true)\n",
            " |-- total_amount: decimal(10,3) (nullable = true)\n",
            " |-- store_and_fwd_flag: boolean (nullable = true)\n",
            " |-- dispatched: boolean (nullable = true)\n",
            " |-- yellow: boolean (nullable = true)\n",
            " |-- tripdays: integer (nullable = true)\n",
            " |-- refunded_flag: boolean (nullable = true)\n",
            " |-- mta_tax: boolean (nullable = true)\n",
            " |-- improvement_surcharge: boolean (nullable = true)\n",
            " |-- mta_tax_fee: decimal(11,1) (nullable = false)\n",
            " |-- surchage_fee: decimal(11,1) (nullable = false)\n",
            " |-- sum_costs: decimal(17,3) (nullable = true)\n",
            " |-- totals_diff: decimal(18,3) (nullable = true)\n",
            " |-- trip_time_sec: long (nullable = true)\n",
            " |-- flag_maxi_taxi: boolean (nullable = false)\n",
            " |-- flag_lg_taxi: boolean (nullable = false)\n",
            " |-- flag_no_passenger: boolean (nullable = false)\n",
            " |-- flag_short_trip: boolean (nullable = false)\n",
            " |-- flag_near_two_error: boolean (nullable = false)\n",
            " |-- trip_time_min: decimal(20,6) (nullable = true)\n",
            " |-- trip_meta: decimal(34,6) (nullable = true)\n",
            " |-- PU_day_of_data: integer (nullable = true)\n",
            " |-- PU_year: integer (nullable = true)\n",
            " |-- PU_month_of_year: integer (nullable = true)\n",
            " |-- PU_week_of_year: integer (nullable = true)\n",
            " |-- PU_day_of_month: integer (nullable = true)\n",
            " |-- PU_day_of_week: integer (nullable = true)\n",
            " |-- PU_hour_of_day: integer (nullable = true)\n",
            " |-- PU_min_of_hour: integer (nullable = true)\n",
            " |-- trip_time_hour: decimal(23,9) (nullable = true)\n",
            " |-- PU_year_of_data: integer (nullable = false)\n",
            " |-- PU_min_of_day: integer (nullable = true)\n",
            " |-- trip_avg_speed: decimal(38,22) (nullable = true)\n",
            " |-- PU_month_of_data: integer (nullable = true)\n",
            " |-- PU_week_of_data: integer (nullable = true)\n",
            " |-- PU_day_of_year: integer (nullable = true)\n",
            " |-- PUBorough: string (nullable = true)\n",
            " |-- PUZone: string (nullable = true)\n",
            " |-- PUServiceZone: string (nullable = true)\n",
            " |-- DOBorough: string (nullable = true)\n",
            " |-- DOZone: string (nullable = true)\n",
            " |-- DOServiceZone: string (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8Tk-SzVAxmZ"
      },
      "source": [
        "zonejoined = zonejoined.drop('trip_avg_speed')\n",
        "zonejoined.createOrReplaceTempView(\"zonejoined_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZa3_T0mAxmZ",
        "outputId": "3dbe5b27-79ad-43fc-fddd-fa35b0ebfdcc"
      },
      "source": [
        "# recast speed\n",
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW checknew_view AS\n",
        "        SELECT *, CAST(ROUND((trip_distance / trip_time_hour), 2) AS DECIMAL(10,2)) AS trip_avg_speed\n",
        "        FROM zonejoined_view\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETs5X3pOAxmb",
        "outputId": "355585b5-c544-49ea-f2db-45689f1f7264"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        SELECT trip_avg_speed\n",
        "        FROM checknew_view\n",
        "        \"\"\").summary().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+----------------+\n",
            "|summary|  trip_avg_speed|\n",
            "+-------+----------------+\n",
            "|  count|          360628|\n",
            "|   mean|       14.783688|\n",
            "| stddev|125.787304080096|\n",
            "|    min|            0.02|\n",
            "|    25%|            9.06|\n",
            "|    50%|           11.75|\n",
            "|    75%|           15.75|\n",
            "|    max|        32040.32|\n",
            "+-------+----------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktzdY7-aDIRf"
      },
      "source": [
        "checkmeta = spark.sql(\"\"\"\n",
        "                        SELECT *\n",
        "                        FROM checknew_view\n",
        "                        \"\"\").drop(\"trip_meta\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZllGVXjDJwG"
      },
      "source": [
        "checkmeta.createOrReplaceTempView(\"checkmeta_view\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ZpxsE3DOc6"
      },
      "source": [
        "spark.sql(\"\"\"\n",
        "        CREATE OR REPLACE TEMP VIEW tripmeta AS\n",
        "        SELECT *,\n",
        "        ((trip_time_min * trip_distance)/2) AS trip_meta\n",
        "        FROM checkmeta_view\n",
        "        \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZaOeHcIDUOy"
      },
      "source": [
        "tripmeta = spark.sql(\"\"\"\n",
        "                    SELECT trip_meta, fare_amount, pickup_datetime, PU_week_of_data, RatecodeID, PUBorough, yellow\n",
        "                    FROM tripmeta\n",
        "                    \"\"\").sample(fraction = 0.001).toPandas()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGAYEJEaAxmk"
      },
      "source": [
        "featureout = spark.sql(\"\"\"\n",
        "                    SELECT *\n",
        "                    FROM tripmeta\n",
        "                    WHERE fare_amount >= 2.5\n",
        "                    AND trip_avg_speed > 0\n",
        "                    AND trip_avg_speed <= 60\n",
        "                    CLUSTER BY yellow, RatecodeID, PU_year_of_data, PU_month_of_data, pickup_datetime\n",
        "                    \"\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzY-_wu-Axml"
      },
      "source": [
        "featureout.write.partitionBy(\"yellow\",\"RatecodeID\",\"PU_year_of_data\", \"PU_month_of_data\").parquet(\"./data/featureout.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiAwFO6uAxml"
      },
      "source": [
        "featureout = spark.read.parquet(\"./data/featureout.parquet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDg5xZGMAxmm",
        "outputId": "ed210fd6-9b13-46fc-8c3e-1957a0a4bdba"
      },
      "source": [
        "featureout.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- VendorID: byte (nullable = true)\n",
            " |-- pickup_datetime: timestamp (nullable = true)\n",
            " |-- dropoff_datetime: timestamp (nullable = true)\n",
            " |-- passenger_count: byte (nullable = true)\n",
            " |-- trip_distance: decimal(10,3) (nullable = true)\n",
            " |-- PULocationID: short (nullable = true)\n",
            " |-- DOLocationID: short (nullable = true)\n",
            " |-- payment_type: byte (nullable = true)\n",
            " |-- fare_amount: decimal(10,3) (nullable = true)\n",
            " |-- extra: decimal(10,3) (nullable = true)\n",
            " |-- tip_amount: decimal(10,3) (nullable = true)\n",
            " |-- tolls_amount: decimal(10,3) (nullable = true)\n",
            " |-- total_amount: decimal(10,3) (nullable = true)\n",
            " |-- store_and_fwd_flag: boolean (nullable = true)\n",
            " |-- dispatched: boolean (nullable = true)\n",
            " |-- tripdays: integer (nullable = true)\n",
            " |-- refunded_flag: boolean (nullable = true)\n",
            " |-- mta_tax: boolean (nullable = true)\n",
            " |-- improvement_surcharge: boolean (nullable = true)\n",
            " |-- mta_tax_fee: decimal(11,1) (nullable = true)\n",
            " |-- surchage_fee: decimal(11,1) (nullable = true)\n",
            " |-- sum_costs: decimal(17,3) (nullable = true)\n",
            " |-- totals_diff: decimal(18,3) (nullable = true)\n",
            " |-- trip_time_sec: long (nullable = true)\n",
            " |-- flag_maxi_taxi: boolean (nullable = true)\n",
            " |-- flag_lg_taxi: boolean (nullable = true)\n",
            " |-- flag_no_passenger: boolean (nullable = true)\n",
            " |-- flag_short_trip: boolean (nullable = true)\n",
            " |-- flag_near_two_error: boolean (nullable = true)\n",
            " |-- trip_time_min: decimal(20,6) (nullable = true)\n",
            " |-- PU_day_of_data: integer (nullable = true)\n",
            " |-- PU_year: integer (nullable = true)\n",
            " |-- PU_month_of_year: integer (nullable = true)\n",
            " |-- PU_week_of_year: integer (nullable = true)\n",
            " |-- PU_day_of_month: integer (nullable = true)\n",
            " |-- PU_day_of_week: integer (nullable = true)\n",
            " |-- PU_hour_of_day: integer (nullable = true)\n",
            " |-- PU_min_of_hour: integer (nullable = true)\n",
            " |-- trip_time_hour: decimal(23,9) (nullable = true)\n",
            " |-- PU_min_of_day: integer (nullable = true)\n",
            " |-- PU_week_of_data: integer (nullable = true)\n",
            " |-- PU_day_of_year: integer (nullable = true)\n",
            " |-- PUBorough: string (nullable = true)\n",
            " |-- PUZone: string (nullable = true)\n",
            " |-- PUServiceZone: string (nullable = true)\n",
            " |-- DOBorough: string (nullable = true)\n",
            " |-- DOZone: string (nullable = true)\n",
            " |-- DOServiceZone: string (nullable = true)\n",
            " |-- trip_avg_speed: decimal(10,2) (nullable = true)\n",
            " |-- trip_meta: decimal(33,11) (nullable = true)\n",
            " |-- yellow: string (nullable = true)\n",
            " |-- RatecodeID: integer (nullable = true)\n",
            " |-- PU_year_of_data: integer (nullable = true)\n",
            " |-- PU_month_of_data: integer (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}